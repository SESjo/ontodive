[{"path":"sesjo.github.io/ontodive/articles/buoyancy_detect.html","id":"daily-median-drift-rate-calculation","dir":"Articles","previous_headings":"","what":"Daily median drift rate calculation","title":"Changes in Buoyancy Detection","text":"summarize data calculating median driftrate day. Median daily drift rate seals (10 random rows) Evolution daily median drift rate across time seals","code":"# calulate the median of driftrate for each day median_driftrate <- data_2018_filter[divetype == \"2: drift\",   .(driftrate = quantile(driftrate, 0.5)),   by = .(date = as.Date(date), .id) ]  # display 10 random rows median_driftrate[sample(.N, 10), ] %>%   sable(caption = \"Median of daily drift rate by seals (10 random rows)\") # display the result ggplot(   median_driftrate,   aes(x = date, y = driftrate, col = .id) ) +   geom_point() +   labs(y = \"Daily drift rate (m/s)\", x = \"Date\") +   theme_jjo() +   theme(legend.position = \"top\")"},{"path":"sesjo.github.io/ontodive/articles/buoyancy_detect.html","id":"model-daily-median-drift-rate-using-a-loess","dir":"Articles","previous_headings":"","what":"Model daily median drift rate using a LOESS","title":"Changes in Buoyancy Detection","text":"seal, model daily median drift rate using local polynomial regression. parameter estimate span, chosen graphically Evolution daily median drift rate across time seals smooth","code":"# display the result ggplot(   median_driftrate,   aes(x = date, y = driftrate, col = .id) ) +   geom_point() +   geom_smooth(span = 0.25, col = \"black\") +   scale_x_date(date_labels = \"%m/%Y\") +   labs(y = \"Daily drift rate (m/s)\", x = \"Date\") +   theme_jjo() +   theme(legend.position = \"top\") +   facet_wrap(. ~ .id, scales = \"free\")"},{"path":"sesjo.github.io/ontodive/articles/buoyancy_detect.html","id":"detection-of-changes-in-buoyancy","dir":"Articles","previous_headings":"","what":"Detection of changes in buoyancy","title":"Changes in Buoyancy Detection","text":"finally identify smooth function change sign. Evolution daily median drift rate across time seals smooth vertical lines identify changes buoyancy","code":"# let's identity when the smooth changes sign changes_driftrate <- median_driftrate %>%   .[, .(     y_smooth = predict(loess(driftrate ~ as.numeric(date), span = 0.25)),     date   ), by = .id] %>%   .[c(FALSE, diff(sign(y_smooth)) != 0), ]  # display the result ggplot(   median_driftrate,   aes(x = date, y = driftrate, col = .id) ) +   geom_point() +   geom_smooth(span = 0.25) +   geom_vline(data = changes_driftrate, aes(xintercept = date)) +   scale_x_date(date_labels = \"%m/%Y\") +   labs(y = \"Daily drift rate (m/s)\", x = \"Date\") +   theme_jjo() +   theme(legend.position = \"top\") +   facet_wrap(. ~ .id, scales = \"free\")"},{"path":"sesjo.github.io/ontodive/articles/create_logo.html","id":"load-r-package","dir":"Articles","previous_headings":"","what":"Load R package","title":"Logo Design","text":"hexSticker: allows build sticker showtext: allows use various types fonts","code":"# loading library library(hexSticker) library(showtext)  # automatically use showtext to render text for future devices showtext_auto()"},{"path":"sesjo.github.io/ontodive/articles/create_logo.html","id":"look-for-the-right-image","dir":"Articles","previous_headings":"","what":"Look for the right image","title":"Logo Design","text":"part mandatory since can use graph instead image. logo, used vector graphic found freesvg.org ’ve modified bit reach needs.","code":""},{"path":"sesjo.github.io/ontodive/articles/create_logo.html","id":"build-your-sticker","dir":"Articles","previous_headings":"","what":"Build your sticker","title":"Logo Design","text":"logo!!","code":"# load the right font font_add_google(\"Courier Prime\")  # print print(   sticker(     \"https://i.imgur.com/QUzPuJK.png\",     package = \"ontodive\",     p_family = \"Courier Prime\",     p_size = 24,     p_y = .6,     s_x = 1,     s_y = 1.3,     s_width = .8,     h_color = \"#fdc700\",     h_fill = \"#003c6c\",     url = \"sesjo.github.io/ontodive\",     u_color = \"#13a5dc\",     u_size = 5,     spotlight = T,     asp = 0.8,   ) )"},{"path":"sesjo.github.io/ontodive/articles/data_exploration_2018.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Data Exploration NES (1/2) - 2018","text":"Summary diving information relative 2018 individual nice dataset :)","code":"# raw_data data_2018[, .(   nb_days_recorded = uniqueN(as.Date(date)),   nb_dives = .N,   maxdepth_mean = mean(maxdepth),   dduration_mean = mean(dduration),   botttime_mean = mean(botttime),   pdi_mean = mean(pdi, na.rm = T) ), by = .id] %>%   sable(     caption = \"Summary diving information relative to each 2018 individual\",     digits = 2   )"},{"path":[]},{"path":"sesjo.github.io/ontodive/articles/data_exploration_2018.html","id":"missing-values","dir":"Articles","previous_headings":"Some explanatory plots","what":"Missing values","title":"Data Exploration NES (1/2) - 2018","text":"Check missing value 2018-individuals far good, variables seems missing values: Percentage missing values per columns missing values!","code":"# build dataset to check for missing values dataPlot <- melt(data_2018[, .(.id, is.na(.SD)), .SDcol = -c(   \".id\",   \"divenumber\",   \"divetype\",   \"date\",   \"phase\",   \"lat\",   \"lon\" )]) # add the id of rows dataPlot[, id_row := c(1:.N), by = c(\"variable\", \".id\")]  # plot ggplot(dataPlot, aes(x = variable, y = id_row, fill = value)) +   geom_tile() +   labs(x = \"Attributes\", y = \"Rows\") +   scale_fill_manual(     values = c(\"white\", \"black\"),     labels = c(\"Real\", \"Missing\")   ) +   facet_wrap(.id ~ ., scales = \"free_y\") +   theme_jjo() +   theme(     legend.position = \"top\",     axis.text.x = element_text(angle = 45, hjust = 1),     legend.key = element_rect(colour = \"black\")   ) # table with percent table_inter <- data_2018[, lapply(.SD, function(x) {   round(length(x[is.na(x)]) * 100 / length(x), 1) }), .SDcol = -c(   \".id\",   \"divenumber\",   \"divetype\",   \"date\",   \"phase\",   \"lat\",   \"lon\" )]  # find which are different from 0 cond_inter <- sapply(table_inter, function(x) {   x == 0 })  # display the percentages that are over 0 table_inter[, which(cond_inter) := NULL] %>%   sable(caption = \"Percentage of missing values per columns having missing values!\") %>%   scroll_box(width = \"100%\")"},{"path":"sesjo.github.io/ontodive/articles/data_exploration_2018.html","id":"outliers","dir":"Articles","previous_headings":"Some explanatory plots","what":"Outliers","title":"Data Exploration NES (1/2) - 2018","text":"Ok, let’s look data. first, remove outliers. quiet easy spot looking distribution dive duration: Distribution dduration seal. dashed line highlight “subjective” threshold used remove outliers (3000 sec) seems much better, let’s remove rows dduration > 3000 sec. # rows removed 2018-individuals","code":"ggplot(   rbind(     copy(data_2018)[, state := \"Before\"],     copy(data_2018)[dduration < 3000, ][, state := \"After\"]   ) %>%     .[, state := factor(state, levels = c(\"Before\", \"After\"))],   aes(x = dduration, fill = .id) ) +   geom_histogram(show.legend = FALSE) +   geom_vline(xintercept = 3000, linetype = \"longdash\") +   facet_grid2(state ~ .id,     scales = \"free\",     independent = \"x\"   ) +   labs(y = \"# of dives\", x = \"Dive duration (s)\") +   theme_jjo() # filter data data_2018_filter <- data_2018[dduration < 3000, ]  # nbrow removed data_2018[dduration >= 3000, .(nb_row_removed = .N), by = .id] %>%   sable(caption = \"# of rows removed by 2018-individuals\")"},{"path":"sesjo.github.io/ontodive/articles/data_exploration_2018.html","id":"check-day-and-night","dir":"Articles","previous_headings":"Some explanatory plots","what":"Check day and night","title":"Data Exploration NES (1/2) - 2018","text":"Light levels Day night detection Visualization light level surface along 2018-individuals’ trip Visualization detected night time day time along 2018-individuals’ trip","code":"# let's first average `lightatsurf` by individuals, day since departure and hour dataPlot <- data_2018[, .(lightatsurf = median(lightatsurf)),   by = .(.id, day_departure, date = as.Date(date), hour = hour(date)) ]  # display the result ggplot(dataPlot, aes(x = day_departure, y = hour, fill = lightatsurf)) +   geom_tile() +   facet_grid(.id ~ .) +   theme_jjo() +   labs(     x = \"# of days since departure\",     y = \"Hour\",     fill = \"Light level at the surface\"   ) +   theme(legend.position = c(\"bottom\")) # let's first average `lightatsurf` by individuals, day since departure and hour dataPlot <- data_2018[, .(lightatsurf = median(lightatsurf)),   by = .(.id,     day_departure,     date = as.Date(date),     hour = hour(date),     phase   ) ]  # display the result ggplot(dataPlot, aes(x = day_departure, y = hour, fill = phase)) +   geom_tile() +   facet_grid(.id ~ .) +   theme_jjo() +   labs(     x = \"# of days since departure\",     y = \"Hour\",     fill = \"Day time and night time as detected by the `cal_phase_day` function\"   ) +   theme(legend.position = c(\"bottom\"))"},{"path":"sesjo.github.io/ontodive/articles/data_exploration_2018.html","id":"all-variables","dir":"Articles","previous_headings":"Some explanatory plots","what":"All Variables","title":"Data Exploration NES (1/2) - 2018","text":"vertical dashed lines represent changes buoyancy (see vignette(\"buoyancy_detect\") information)","code":"names_display <- names(data_2018_filter[, -c(   \".id\",   \"date\",   \"divenumber\",   \"divetype\",   \"day_departure\",   \"phase\",   \"lat\",   \"lon\",   \"dist_dep\",   \"sp\" )])  # calulate the median of driftrate for each day median_driftrate <- data_2018[divetype == \"2: drift\",   .(driftrate = quantile(driftrate, 0.5)),   by = .(date = as.Date(date), .id) ]  # let's identity when the smooth changes sign changes_driftrate <- median_driftrate %>%   .[, .(     y_smooth = predict(loess(driftrate ~ as.numeric(date), span = 0.25)),     date   ), by = .id] %>%   .[c(FALSE, diff(sign(y_smooth)) != 0), ] for (i in names_display) {   cat(\"####\", i, \"{.unlisted .unnumbered} \\n\")   if (i == \"driftrate\") {     print(       ggplot(         data = melt(data_2018_filter[, .(.id, date, get(i), divetype)],           id.vars = c(\".id\", \"date\", \"divetype\")         ),         aes(           x = as.Date(date),           y = value,           col = divetype         )       ) +         geom_point(           alpha = 1 / 10,           size = .5         ) +         geom_vline(           data = changes_driftrate,           aes(xintercept = date),           linetype = 2         ) +         facet_wrap(. ~ .id, scales = \"free\") +         scale_x_date(date_labels = \"%m/%Y\") +         labs(x = \"Date\", y = \"Drift Rate 'm/s\", col = \"Dive Type\") +         theme_jjo() +         theme(           axis.text.x = element_text(angle = 45, hjust = 1),           legend.position = \"bottom\"         ) +         guides(colour = guide_legend(override.aes = list(           size = 7,           alpha = 1         )))     )   } else {     print(       ggplot(         data = melt(data_2018_filter[, .(.id, date, get(i))],           id.vars = c(\".id\", \"date\")         ),         aes(           x = as.Date(date),           y = value,           col = .id         )       ) +         geom_point(           show.legend = FALSE,           alpha = 1 / 10,           size = .5         ) +         geom_vline(           data = changes_driftrate,           aes(xintercept = date),           linetype = 2         ) +         geom_vline(data = dataVline, aes(xintercept = as.Date(date)), colour = \"black\", linetype = 2) +         facet_wrap(. ~ .id, scales = \"free\") +         scale_x_date(date_labels = \"%m/%Y\") +         labs(x = \"Date\", y = i) +         theme_jjo() +         theme(axis.text.x = element_text(angle = 45, hjust = 1))     )   }    cat(\"\\n \\n\") }"},{"path":"sesjo.github.io/ontodive/articles/data_exploration_2018.html","id":"section","dir":"Articles","previous_headings":"","what":"Data Exploration NES (1/2) - 2018","title":"Data Exploration NES (1/2) - 2018","text":"maxdepth dduration botttime desctime descrate asctime ascrate pdi dwigglesdesc dwigglesbott dwigglesasc totvertdistbot driftrate lightatsurf ssh psu vel temp bathy","code":""},{"path":"sesjo.github.io/ontodive/articles/data_exploration_2018.html","id":"section-1","dir":"Articles","previous_headings":"","what":"Data Exploration NES (1/2) - 2018","title":"Data Exploration NES (1/2) - 2018","text":"questions, look : bimodal distribution dduration, desctime due nycthemeral migration? bimodal distribution descrate (especially ind2018070 ind_2018072) due drift dive? lightatbott used identify bioluminescence, cause seems lot going bottom? variations observed lightatsurf due moon cycle? sure bimodal distribution tempatbott! driftrate one awesome! Thanks divetype can clearly see pattern driftrate (buoyancy) change according time. vertical dashed lines represent changes buoyancy (see vignette(\"buoyancy_detect\") information)","code":"# same plot with a colored for the phase of the day for (i in names_display) {   cat(\"####\", i, \"{-} \\n\")   print(     ggplot(       data = melt(data_2018_filter[, .(.id, date, get(i), phase)],         id.vars = c(           \".id\",           \"date\",           \"phase\"         )       ),       aes(         x = as.Date(date),         y = value,         col = phase       )     ) +       geom_point(         alpha = 1 / 10,         size = .5       ) +       geom_vline(         data = changes_driftrate,         aes(xintercept = date),         linetype = 2       ) +       facet_wrap(. ~ .id, scales = \"free\") +       scale_x_date(date_labels = \"%m/%Y\") +       labs(x = \"Date\", y = i) +       theme_jjo() +       theme(         axis.text.x = element_text(angle = 45, hjust = 1),         legend.position = \"bottom\"       ) +       guides(colour = guide_legend(override.aes = list(         size = 7,         alpha = 1       )))   )   cat(\"\\n \\n\") }"},{"path":"sesjo.github.io/ontodive/articles/data_exploration_2018.html","id":"section-2","dir":"Articles","previous_headings":"","what":"Data Exploration NES (1/2) - 2018","title":"Data Exploration NES (1/2) - 2018","text":"maxdepth dduration botttime desctime descrate asctime ascrate pdi dwigglesdesc dwigglesbott dwigglesasc totvertdistbot driftrate lightatsurf ssh psu vel temp bathy","code":""},{"path":"sesjo.github.io/ontodive/articles/data_exploration_2018.html","id":"all-variables-during-the-first-month","dir":"Articles","previous_headings":"Some explanatory plots","what":"All Variables during the first month","title":"Data Exploration NES (1/2) - 2018","text":"","code":"for (i in names_display) {   cat(\"####\", i, \"{.unlisted .unnumbered} \\n\")   print(     ggplot(       data = melt(         data_2018_filter[           day_departure < 32,           .(.id, day_departure, get(i))         ],         id.vars = c(\".id\", \"day_departure\")       ),       aes(         x = day_departure,         y = value,         color = .id,         group = day_departure       )     ) +       geom_boxplot(         show.legend = FALSE,         alpha = 1 / 10,         size = .5       ) +       facet_wrap(. ~ .id, scales = \"free\") +       labs(x = \"# days since departure\", y = i) +       theme_jjo()   )   cat(\"\\n \\n\") }"},{"path":"sesjo.github.io/ontodive/articles/data_exploration_2018.html","id":"section-3","dir":"Articles","previous_headings":"","what":"Data Exploration NES (1/2) - 2018","title":"Data Exploration NES (1/2) - 2018","text":"maxdepth dduration botttime desctime descrate asctime ascrate pdi dwigglesdesc dwigglesbott dwigglesasc totvertdistbot driftrate lightatsurf ssh psu vel temp bathy","code":""},{"path":"sesjo.github.io/ontodive/articles/data_exploration_2018.html","id":"section-4","dir":"Articles","previous_headings":"","what":"Data Exploration NES (1/2) - 2018","title":"Data Exploration NES (1/2) - 2018","text":"","code":"for (i in names_display) {   cat(\"####\", i, \"{.unlisted .unnumbered} \\n\")   print(     ggplot(       data = melt(         data_2018_filter[           day_departure < 32,           .(.id, day_departure, get(i), phase)         ],         id.vars = c(\".id\", \"day_departure\", \"phase\")       ),       aes(         x = day_departure,         y = value,         color = phase,         group = interaction(day_departure, phase),       )     ) +       geom_boxplot(         alpha = 1 / 10,         size = .5       ) +       facet_wrap(. ~ .id, scales = \"free\") +       labs(x = \"# days since departure\", y = i) +       theme_jjo() +       theme(legend.position = \"bottom\")   )   cat(\"\\n \\n\") }"},{"path":"sesjo.github.io/ontodive/articles/data_exploration_2018.html","id":"section-5","dir":"Articles","previous_headings":"","what":"Data Exploration NES (1/2) - 2018","title":"Data Exploration NES (1/2) - 2018","text":"maxdepth dduration botttime desctime descrate asctime ascrate pdi dwigglesdesc dwigglesbott dwigglesasc totvertdistbot driftrate lightatsurf ssh psu vel temp bathy","code":""},{"path":"sesjo.github.io/ontodive/articles/data_exploration_2018.html","id":"correlation","dir":"Articles","previous_headings":"Some explanatory plots","what":"Correlation","title":"Data Exploration NES (1/2) - 2018","text":"Can find nice correlation? Correlation matrix (crosses indicate non significant correlation) Another way see : Pairwise correlation 0.75 associated p-values guess nothing unexpected ;)","code":"# compute correlation corr_2018 <- round(cor(data_2018_filter[, names_display, with = F],   use = \"pairwise.complete.obs\" ), 1)  # replace NA value by 0 corr_2018[is.na(corr_2018)] <- 0  # compute p_values corr_p_2018 <- cor_pmat(data_2018_filter[, names_display, with = F])  # replace NA value by 0 corr_p_2018[is.na(corr_p_2018)] <- 1  # display ggcorrplot(   corr_2018,   p.mat = corr_p_2018,   hc.order = TRUE,   method = \"circle\",   type = \"lower\",   ggtheme = theme_jjo(),   sig.level = 0.05,   colors = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\") ) # flatten correlation matrix cor_result_2018 <- flat_cor_mat(corr_2018, corr_p_2018)  # keep only the one above .7 cor_result_2018[cor >= .7, ][order(-abs(cor))] %>%   sable(caption = \"Pairwise correlation above 0.75 and associated p-values\")"},{"path":"sesjo.github.io/ontodive/articles/data_exploration_2018.html","id":"dive-type","dir":"Articles","previous_headings":"","what":"Dive Type","title":"Data Exploration NES (1/2) - 2018","text":"Proportion dive types","code":"# dataset to plot proportional area plot dataPlot <- data_2018_filter %>%   .[, .(sum_id_days = .N), by = .(.id, day_departure, divetype)] %>%   .[, prop := sum_id_days / sum(sum_id_days), by = .(.id, day_departure)]  # area plot ggplot(dataPlot, aes(   x = as.numeric(day_departure),   y = prop,   fill = as.character(divetype) )) +   geom_area(alpha = 0.6, size = 1, position = \"stack\", stat = \"identity\") +   facet_wrap(.id ~ ., scales = \"free\") +   scale_y_continuous(labels = scales::percent) +   theme_jjo() +   theme(legend.position = \"bottom\") +   labs(     x = \"# of days since departure\",     y = \"Proportion of dives\",     fill = \"Dive types\"   )"},{"path":"sesjo.github.io/ontodive/articles/data_exploration_2018.html","id":"dive-duration-vs--maximum-depth","dir":"Articles","previous_headings":"","what":"Dive duration vs. Maximum depth","title":"Data Exploration NES (1/2) - 2018","text":"Colored ID Colored Dive Type Colored # days since departure Colored phases day Dive duration vs. Maximum Depth colored 2018-individuals Dive duration vs. Maximum Depth colored Dive Type Dive duration vs. Maximum Depth colored # days since departure Dive duration vs. Maximum Depth colored phases day seems patch high depths (especially visible ind2018070), don’t know linked …","code":"# plot ggplot(data = data_2018_filter, aes(y = dduration, x = maxdepth, col = .id)) +   geom_point(size = .5, alpha = .1, show.legend = FALSE) +   facet_wrap(.id ~ .) +   labs(x = \"Maximum depth (m)\", y = \"Dive duration (s)\") +   theme_jjo() # plot ggplot(data = data_2018_filter, aes(   y = dduration,   x = maxdepth,   col = divetype )) +   geom_point(size = .5, alpha = .1) +   facet_wrap(.id ~ .) +   guides(colour = guide_legend(override.aes = list(size = 5, alpha = 1))) +   labs(x = \"Maximum depth (m)\", y = \"Dive duration (s)\") +   theme_jjo() +   theme(legend.position = \"bottom\") # plot ggplot(   data = data_2018_filter[, prop_track := (day_departure * 100) / max(day_departure), by = .id],   aes(y = dduration, x = maxdepth, col = prop_track) ) +   geom_point(size = .5, alpha = .1) +   facet_wrap(.id ~ .) +   labs(     x = \"Maximum depth (m)\",     y = \"Dive duration (s)\",     col = \"Proportion of completed track (%)\"   ) +   scale_color_continuous(type = \"viridis\") +   theme_jjo() +   theme(legend.position = \"bottom\") # plot ggplot(data = data_2018_filter, aes(y = dduration, x = maxdepth, col = phase)) +   geom_point(size = .5, alpha = .1) +   facet_wrap(.id ~ .) +   guides(colour = guide_legend(override.aes = list(size = 5, alpha = 1))) +   labs(     x = \"Maximum depth (m)\",     y = \"Dive duration (s)\",     col = \"Phases of the day\"   ) +   theme_jjo() +   theme(legend.position = \"bottom\")"},{"path":"sesjo.github.io/ontodive/articles/data_exploration_2018.html","id":"drift-rate","dir":"Articles","previous_headings":"","what":"Drift Rate","title":"Data Exploration NES (1/2) - 2018","text":"following graphs: driftrate calculated using divetype == \"2: drift\" whereas others variables calculated dives considered Drift rate vs. Bottom time Drift rate vs. Maximum depth Drift rate vs. Dive duration","code":"# build dataset dataPlot <- data_2018_filter[divetype == \"2: drift\",   # median drift rate for drift dive   .(driftrate = median(driftrate, na.rm = T)),   by = .(.id, day_departure) ] %>%   .[     data_2018_filter[,       .(         # median dive duration all dives considered         dduration = median(dduration, na.rm = T),         # median max depth all dives considered         maxdepth = median(maxdepth, na.rm = T),         # median bottom dives all dives considered         botttime = median(botttime, na.rm = T)       ),       by = .(.id, day_departure)     ],     on = c(\".id\", \"day_departure\")   ] # plot ggplot(dataPlot, aes(x = botttime, y = driftrate, col = .id)) +   geom_point(size = .5, alpha = .5) +   geom_smooth(method = \"lm\") +   guides(color = \"none\") +   facet_wrap(.id ~ .) +   scale_x_continuous(limits = c(0, 700)) +   labs(     x = \"Daily median Bottom time (s)\",     y = \"Daily median drift rate (m.s-1)\"   ) +   theme_jjo() # plot ggplot(dataPlot, aes(x = maxdepth, y = driftrate, col = .id)) +   geom_point(size = .5, alpha = .5) +   geom_smooth(method = \"lm\") +   guides(color = \"none\") +   facet_wrap(.id ~ .) +   labs(     x = \"Daily median Maximum depth (m)\",     y = \"Daily median drift rate (m.s-1)\"   ) +   theme_jjo() # plot ggplot(dataPlot, aes(x = dduration, y = driftrate, col = .id)) +   geom_point(size = .5, alpha = .5) +   geom_smooth(method = \"lm\") +   guides(color = \"none\") +   facet_wrap(.id ~ .) +   labs(     x = \"Daily median Dive duration (s)\",     y = \"Daily median drift rate (m.s-1)\"   ) +   theme_jjo()"},{"path":[]},{"path":"sesjo.github.io/ontodive/articles/data_exploration_2018.html","id":"cook-et-al-2008","dir":"Articles","previous_headings":"Behavioral Aerobic Dive Limit (bADL)","what":"Cook et al (2008)","title":"Data Exploration NES (1/2) - 2018","text":"Post-dive duration vs. dive duration Post-dive duration vs. dive duration (raw data) Post-dive duration / dive duration ratio vs. day since departure","code":"# dive duration vs pdi by days ggplot(data = data_2018_filter[pdi < 300, ], aes(   x = dduration,   y = pdi,   color = .id,   group = dduration,   fill = \"none\" )) +   geom_boxplot(show.legend = FALSE, outlier.alpha = 0.05, alpha = 0) +   labs(x = \"Dive duration (s)\", y = \"Post-dive duration (s)\") +   facet_wrap(. ~ .id, scales = \"free_x\") +   theme_jjo() # dive duration vs pdi by days ggplot(data = data_2018_filter[pdi < 300, ], aes(   x = dduration,   y = pdi,   color = .id )) +   geom_point(show.legend = FALSE, alpha = 0.05) +   geom_smooth(     method = \"gam\",     show.legend = FALSE,     col = \"black\",     linetype = \"dashed\"   ) +   labs(x = \"Dive duration (s)\", y = \"Post-dive duration (s)\") +   facet_wrap(. ~ .id, scales = \"free_x\") +   theme_jjo() # dive duration vs pdi by days ggplot(   data = data_2018_filter[pdi < 300, .(.id, pdi_ratio = pdi / dduration, day_departure)],   aes(     x = day_departure,     y = pdi_ratio,     color = .id,     group = day_departure,     fill = \"none\"   ) ) +   geom_boxplot(     show.legend = FALSE,     outlier.alpha = 0.05,     alpha = 0   ) +   labs(x = \"# days since departure\", y = \"Post-dive / Dive duration ratio\") +   facet_wrap(. ~ .id, scales = \"free_x\") +   # zoom   coord_cartesian(ylim = c(0, 0.4)) +   theme_jjo()"},{"path":"sesjo.github.io/ontodive/articles/data_exploration_2018.html","id":"shero-et-al--2018","dir":"Articles","previous_headings":"Behavioral Aerobic Dive Limit (bADL)","what":"Shero et al. (2018)","title":"Data Exploration NES (1/2) - 2018","text":"Based Shero et al. (2018), decided look bADL 95th percentile dive duration day, \\(n \\geq 50\\). threshold chosen following figure: Distribution number dives day. threshold used calculate bADL fixed 50 dives per day. Behavioral ADL vs. drift rate along animals’ trip (one seeing kind relationship?) Looking graph, want believe kind relationship bADL defined Shero et al. (2018) drift rate (buyoancy).","code":"ggplot(   data_2018_filter[, .(nb_dives = .N),     by = .(.id, day_departure)   ],   aes(x = nb_dives, fill = .id) ) +   geom_histogram(show.legend = FALSE) +   geom_vline(xintercept = 50, linetype = \"dashed\") +   facet_grid(. ~ .id) +   labs(y = \"# of days\", x = \"# of dives per day\") +   theme_jjo() # select day that have at least 50 dives days_to_keep <- data_2018_filter[,   .(nb_dives = .N),   by = .(.id, day_departure) ] %>%   .[nb_dives >= 50, ]  # keep only those days data_2018_filter_complete_day <- merge(data_2018_filter,   days_to_keep,   by = c(\".id\", \"day_departure\") )  # data plot dataPlot <- data_2018_filter_complete_day[divetype == \"1: foraging\",   .(badl = quantile(dduration, 0.95)),   by = .(.id, day_departure) ]  # combine two datasets to be able to use a second axis # https://stackoverflow.com/questions/49185583/two-y-axes-with-different-scales-for-two-datasets-in-ggplot2 dataMegaPlot <- rbind(   data_2018_filter_complete_day[divetype == \"2: drift\"] %>%     .[, .(       w = .id,       y = driftrate,       x = day_departure,       z = \"second_plot\"     )],   dataPlot[, .(     w = .id,     # tricky one     y = (badl / 1000) - 1,     x = day_departure,     z = \"first_plot\"   )] )  # plot ggplot() +   geom_point(     data = dataMegaPlot[z == \"second_plot\", ],     aes(x = x, y = y),     alpha = 1 / 10,     size = 0.5,     color = \"grey40\",     show.legend = FALSE   ) +   geom_path(     data = dataMegaPlot[z == \"first_plot\", ],     aes(x = x, y = y, color = w),     show.legend = FALSE   ) +   scale_y_continuous(     # Features of the first axis     name = \"Drift rate (m/s)\",     # Add a second axis and specify its features     sec.axis = sec_axis(~ (. * 1000) + 1000,       name = \"Behavioral Aerobic Dive Limit (s)\"     )   ) +   labs(x = \"# days since departure\") +   facet_wrap(w ~ .) +   theme_jjo() # get badl dataplot_1 <- data_2018_filter_complete_day[,   .(badl = quantile(dduration, 0.95)),   by = .(.id, day_departure) ] # get driftrate dataplot_2 <- data_2018_filter_complete_day[divetype == \"2: drift\",   .(driftrate = median(driftrate)),   by = .(.id, day_departure) ]  # merge dataPlot <- merge(dataplot_1,   dataplot_2,   by = c(\".id\", \"day_departure\"),   all = TRUE )  # plot ggplot(data = dataPlot, aes(x = badl, y = driftrate, col = .id)) +   geom_point(show.legend = FALSE) +   facet_wrap(.id ~ ., scales = \"free\") +   theme_jjo()"},{"path":"sesjo.github.io/ontodive/articles/data_exploration_2018.html","id":"section-6","dir":"Articles","previous_headings":"","what":"Data Exploration NES (1/2) - 2018","title":"Data Exploration NES (1/2) - 2018","text":"ind_2018070 ind_2018072 ind_2018074 ind_2018072","code":"# ind_2018070 plot_ly(   x = dataPlot[.id == \"ind_2018070\", badl],   y = dataPlot[.id == \"ind_2018070\", day_departure],   z = dataPlot[.id == \"ind_2018070\", driftrate],   type = \"scatter3d\",   mode = \"markers\",   marker = list(size = 2),   color = dataPlot[.id == \"ind_2018070\", day_departure] ) %>%   layout(scene = list(     xaxis = list(title = \"Behavioral ADL\"),     yaxis = list(title = \"# days since departure\"),     zaxis = list(title = \"Drift rate (m/s)\")   )) # ind_2018072 plot_ly(   x = dataPlot[.id == \"ind_2018072\", badl],   y = dataPlot[.id == \"ind_2018072\", day_departure],   z = dataPlot[.id == \"ind_2018072\", driftrate],   type = \"scatter3d\",   mode = \"markers\",   marker = list(size = 2),   color = dataPlot[.id == \"ind_2018072\", day_departure] ) %>%   layout(scene = list(     xaxis = list(title = \"Behavioral ADL\"),     yaxis = list(title = \"# days since departure\"),     zaxis = list(title = \"Drift rate (m/s)\")   )) # ind_2018074 plot_ly(   x = dataPlot[.id == \"ind_2018074\", badl],   y = dataPlot[.id == \"ind_2018074\", day_departure],   z = dataPlot[.id == \"ind_2018074\", driftrate],   type = \"scatter3d\",   mode = \"markers\",   marker = list(size = 2),   color = dataPlot[.id == \"ind_2018074\", day_departure] ) %>%   layout(scene = list(     xaxis = list(title = \"Behavioral ADL\"),     yaxis = list(title = \"# days since departure\"),     zaxis = list(title = \"Drift rate (m/s)\")   )) # ind_2018080 plot_ly(   x = dataPlot[.id == \"ind_2018080\", badl],   y = dataPlot[.id == \"ind_2018080\", day_departure],   z = dataPlot[.id == \"ind_2018080\", driftrate],   type = \"scatter3d\",   mode = \"markers\",   marker = list(size = 2),   color = dataPlot[.id == \"ind_2018080\", day_departure] ) %>%   layout(scene = list(     xaxis = list(title = \"Behavioral ADL\"),     yaxis = list(title = \"# days since departure\"),     zaxis = list(title = \"Drift rate (m/s)\")   ))"},{"path":[]},{"path":"sesjo.github.io/ontodive/articles/data_exploration_2018_map.html","id":"general-maps","dir":"Articles","previous_headings":"GPS data","what":"General Maps","title":"Data Exploration NES (2/2) - 2018","text":"data contrast changes enough marked, treatment applied data remove outliers variable using interquartile range rule. Tracking data 2018 individuals (green red dot respectively indicate beginning end trip)","code":"# This piece of code is only there to show how to draw a polylines with a # gradient color using leaflet. We're not using it due to the size of the # created map, and will continue using circle marker  # datasets used to display map df_driftrate <- unique(data_2018_filter[   .id == \"ind_2018070\" &     divetype == \"2: drift\",   .(.id, lat, lon, dduration) ])  # color palette pal <- colorNumeric(   palette = \"YlGnBu\",   domain = df_driftrate$dduration )  # add df_driftrate[, `:=`(   nextLat = shift(lat),   nextLon = shift(lon),   color = pal(df_driftrate$dduration) )]  # interactive map gradient_map <- leaflet() %>%   setView(lng = -122, lat = 38, zoom = 2) %>%   addTiles()  # add lines for (i in 1:nrow(df_driftrate)) {   gradient_map <- addPolylines(     map = gradient_map,     data = df_driftrate,     lat = as.numeric(df_driftrate[i, c(\"lat\", \"nextLat\")]),     lng = as.numeric(df_driftrate[i, c(\"lon\", \"nextLon\")]),     color = df_driftrate[i, color],     weight = 3,     group = \"individual_1\"   ) }  # add layer control gradient_map <- addLayersControl(   map = gradient_map,   overlayGroups = c(\"individual_1\"),   options = layersControlOptions(collapsed = FALSE) ) # interactive map gradient_map <- leaflet() %>%   setView(lng = -132, lat = 48, zoom = 4) %>%   addTiles()  # loop by individuals and variable grps <- NULL for (i in data_2018_filter[!is.na(lat), unique(.id)]) {   for (k in c(\"dduration\", \"driftrate\")) {     if (k == \"driftrate\") {       # set dataset used to plot       dataPlot <- unique(data_2018_filter %>%         .[order(date), ] %>%         .[           .id == i &             divetype == \"2: drift\" &             !is.na(get(k)),           c(\"lat\", \"lon\", k),           with = FALSE         ] %>%         .[!is_outlier(get(k)), ])       # color palette creation       colPal <- colorNumeric(         palette = \"BrBG\",         domain = seq(           -dataPlot[, max(abs(driftrate))],           dataPlot[, max(abs(driftrate))],           0.1         )       )     } else {       # set dataset used to plot       dataPlot <- unique(data_2018_filter %>%         .[order(date), ] %>%         .[           .id == i &             divetype != \"2: drift\" &             !is.na(get(k)),           c(\"lat\", \"lon\", k),           with = FALSE         ] %>%         .[!is_outlier(get(k)), ])       # color palette creation       colPal <- colorNumeric(         palette = \"YlGnBu\",         domain = dataPlot[, get(k)]       )     }      # add color to dataset     dataPlot[, color := colPal(dataPlot[, get(k)])]     # add size column     dataPlot[, radius := 3]     # mark the beginning of the trip     dataPlot[1, `:=`(       color = \"green\",       radius = 4     )]     # mark the end of the trip     dataPlot[.N, `:=`(       color = \"red\",       radius = 4     )]     # reorder to make the end and the beginning in front     dataPlot <- rbind(dataPlot[-1, ], dataPlot[1, ])      # convert to sf     dataPlot <- sf::st_as_sf(dataPlot, coords = c(\"lon\", \"lat\"), crs = 4326)      # add markers to map     gradient_map <- addGlPoints(       map = gradient_map,       data = dataPlot,       radius = dataPlot$radius * 4,       stroke = FALSE,       fillColor = ~color,       group = paste(i, \"-\", k)     ) %>%       addLegend(\"bottomleft\",         data = dataPlot,         group = paste(i, \"-\", k),         pal = colPal,         values = ~ get(k),         title = k       )     # retrieve groups     grps <- c(grps, paste(i, \"-\", k))   } }  # add layer control gradient_map <- addLayersControl(   map = gradient_map,   overlayGroups = grps,   options = layersControlOptions(collapsed = TRUE) ) %>% hideGroup(grps) # display gradient_map # clear memory gc() ##            used  (Mb) gc trigger  (Mb) max used  (Mb) ## Ncells  5303047 283.3   10147818 542.0  6711698 358.5 ## Vcells 16984771 129.6   30289652 231.1 25170713 192.1 rm(   gradient_map,   dataPlot ) gc() ##            used  (Mb) gc trigger  (Mb) max used  (Mb) ## Ncells  5298274 283.0   10147818 542.0  6711698 358.5 ## Vcells 16362435 124.9   30289652 231.1 25170713 192.1"},{"path":"sesjo.github.io/ontodive/articles/data_exploration_2018_map.html","id":"current-velocity-map","dir":"Articles","previous_headings":"GPS data","what":"Current Velocity Map","title":"Data Exploration NES (2/2) - 2018","text":"First need load current data. loaded data Copernicus platform using product Global Ocean Physics Reanalysis allow get estimation current velocity eddies surface spatial resolution 0.083° × 0.083° every day. step might take time since represents lot data. can build animation individual. code executed document compiled, since ’s quite time consuming.","code":"# import the already pre-treated ncdf data(\"data_cop\", package = \"ontodive\") # easier (it's also because it was the only way that works) using a function anim_plot_current <- function(data, id_inter) {   # plot   ggplot() +     geom_raster(       data = data_cop[time %between% c(         data[           .id == id_inter,           min(as.Date(date))         ],         data[           .id == id_inter,           max(as.Date(date))         ]       ) &         longitude %between% c(           data[             .id == id_inter,             min(lon)           ] - 2,           data[             .id == id_inter,             max(lon)           ] + 2         ) &         latitude %between% c(           data[             .id == id_inter,             min(lat)           ] - 2,           data[             .id == id_inter,             max(lat)           ] + 2         )],       aes(x = longitude, y = latitude, fill = vel),       interpolate = TRUE     ) +     geom_point(       data = unique(data[         .id == id_inter,         .(           time = as.Date(date),           lat,           lon         )       ]),       aes(x = lon, y = lat),       color = \"white\"     ) +     geom_sf(       data = spData::world,       col = 1,       fill = \"ivory\"     ) +     coord_sf(       xlim = c(         data[.id == id_inter, min(lon)] - 2,         data[.id == id_inter, max(lon)] + 2       ),       ylim = c(         data[.id == id_inter, min(lat)] - 2,         data[.id == id_inter, max(lat)] + 2       )     ) +     theme_jjo() +     labs(x = NULL, y = NULL) +     scale_fill_gradientn(       colours = oce::oceColors9A(120),       limits = c(0, 1)     ) +     labs(title = paste(id_inter, \"- Date: {frame_time}\")) +     transition_time(time) }  # apply this function to all individuals res_ggplot <- lapply(data_2018_filter[!is.na(lat), unique(.id)],   anim_plot_current,   data = data_2018_filter )  # apply the animation for each individual res_gganimate <- lapply(res_ggplot, function(x) {   animate(x, renderer = magick_renderer()) })  # then to display the first individuals res_gganimate[[1]]  # save the plot anim_save(\"ind_2018070_vel_alltrip.gif\", animation = last_animation())"},{"path":"sesjo.github.io/ontodive/articles/data_exploration_2018_map.html","id":"water-height-map","dir":"Articles","previous_headings":"GPS data","what":"Water Height Map","title":"Data Exploration NES (2/2) - 2018","text":"Another approach look view centered animal (find easier spot relation animal’s track environmental conditions). Let’s look another variable, sea surface geoid (often called SSH Sea Surface Height, called zos hereafter), can used identify eddies. , since step time-consuming, following code run, gives idea generate *.gif. addition, using gganimate generate *.gif file found memory consuming developed individuals another way generate *.gif file. used “old-fashioned” way consisting generating plots compile *.gif file.    Hard tell relation, might need dig deeper, especially ind_2018072 ind_2018080 looking current direction /distribution abundance different trophic level using SEAPODYM.","code":"# get the position of the animal each day gps_day <- data_2018_filter[!is.na(lat), .(date, lat, lon, .id)] %>%   .[, .(     lat = mean(lat, na.rm = T),     lon = mean(lon, na.rm = T)   ),   by = .(.id, time = as.Date(date))   ]  anim_plot_zos_center <- function(id_inter) {   # initiate   df_raster_inter <- data.table()    # example with id_inter   for (i in 1:gps_day[.id == id_inter, .N]) {     # retrieve the right values     time_inter <- gps_day[.id == id_inter, time][i]     lat_inter <- gps_day[.id == id_inter, lat][i]     lon_inter <- gps_day[.id == id_inter, lon][i]      # get the right data     df_raster_inter <- rbind(       df_raster_inter,       data_cop[time == time_inter &         latitude %between% c(           lat_inter - 4,           lat_inter + 4         ) &         longitude %between% c(           lon_inter - 4,           lon_inter + 4         )]     )   }    # release memory   gc()    # plot   plot_animate <- ggplot() +     geom_raster(       data = df_raster_inter[, .(longitude, latitude, zos, time)],       aes(x = longitude, y = latitude, fill = zos)     ) +     geom_path(       data = unique(data_2018_filter[.id == id_inter, .(lat, lon)]),       aes(x = lon, y = lat),       color = \"red\",       size = 2     ) +     geom_point(       data = gps_day[.id == id_inter, ],       aes(x = lon, y = lat),       color = \"white\",       size = 2     ) +     theme_jjo() +     labs(x = NULL, y = NULL) +     scale_fill_gradientn(colours = oce::oceColors9A(120)) +     labs(title = paste(id_inter, \"- Date: {frame_time}\")) +     transition_time(time) +     view_follow(exclude_layer = 2)    # rm   rm(df_raster_inter)    # return   return(plot_animate) }  # apply this function to all individuals res_ggplot_center <- lapply(   data_2018_filter[!is.na(lat), unique(.id)],   anim_plot_zos_center )  # apply the animation for each individual res_gganimate_center <- lapply(res_ggplot_center, function(x) {   animate(x, duration = 20, nframes = 200, renderer = magick_renderer())   gc() })  # first individual res_gganimate_center[[1]]  # save gif file anim_save(\"ind_2018070_zos_center.gif\", animation = last_animation()) another_anim_plot_zos_center <- function(id_inter) {   # example with id_inter   for (i in 1:gps_day[.id == id_inter, .N]) {     # retrieve the right values     time_inter <- gps_day[.id == id_inter, time][i]     lat_inter <- gps_day[.id == id_inter, lat][i]     lon_inter <- gps_day[.id == id_inter, lon][i]      # get the right data     df_raster_inter <- data_cop[time == time_inter &       latitude %between% c(         lat_inter - 4,         lat_inter + 4       ) &       longitude %between% c(         lon_inter - 4,         lon_inter + 4       )]     # plot     p <- ggplot() +       geom_tile(         data = df_raster_inter[, .(longitude, latitude, zos, time)],         aes(x = longitude, y = latitude, fill = zos)       ) +       geom_path(         data = unique(data_2018_filter[.id == id_inter, .(lat, lon)]),         aes(x = lon, y = lat),         color = \"red\",         size = 1.5       ) +       geom_point(         data = gps_day[.id == id_inter, ][i, ],         aes(x = lon, y = lat),         color = \"white\",         size = 2       ) +       theme_jjo() +       theme(axis.text.y = element_text(angle = 90)) +       labs(x = NULL, y = NULL) +       scale_fill_gradientn(colours = oce::oceColors9A(120)) +       labs(title = paste(id_inter, \"- Date: \", time_inter)) +       coord_cartesian(         ylim = c(lat_inter - 4, lat_inter + 4),         xlim = c(lon_inter - 4, lon_inter + 4)       )      # save     ggsave(       plot = p,       filename = paste0(\"./tmp/\", id_inter, \" - Date: \", time_inter, \".png\"),       device = \"png\"     )   } }  # run the function for one individual another_anim_plot_zos_center(\"ind_2018072\")  # compile the gif file gifski(   list.files(\"tmp/\", pattern = \"png$\", full.names = T),   gif_file = \"ind_2018072_zos_center.gif\",   width = 480,   height = 480,   delay = 0.1 )"},{"path":"sesjo.github.io/ontodive/articles/data_exploration_2018_map.html","id":"along-their-trip","dir":"Articles","previous_headings":"","what":"Along their trip","title":"Data Exploration NES (2/2) - 2018","text":"Evolution oceanographic data number days since departure","code":"# evolution with trip at sea ggplot(   melt(     data_2018_filter,     id.vars = c(\".id\", \"day_departure\"),     measure.vars = c(\"temp\", \"ssh\", \"psu\", \"vel\")   ),   aes(     x = day_departure,     y = value,     col = .id   ) ) +   geom_line() +   facet_wrap(variable ~ ., scales = \"free\") +   theme_jjo() +   labs(y = \"Values\", x = \"# of days since departure\") +   theme(legend.position = \"bottom\")"},{"path":"sesjo.github.io/ontodive/articles/data_exploration_ses_2014.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Data Exploration SES - 2014","text":"Summary diving information relative 2018 individual","code":"# raw_data data_2014[, .(   nb_days_recorded = uniqueN(as.Date(date)),   nb_dives = .N,   maxdepth_mean = mean(maxdepth),   dduration_mean = mean(dduration),   botttime_mean = mean(botttime),   pdi_mean = mean(pdi, na.rm = T) ), by = .id] %>%   sable(     caption = \"Summary diving information relative to each 2018 individual\",     digits = 2   )"},{"path":[]},{"path":"sesjo.github.io/ontodive/articles/data_exploration_ses_2014.html","id":"missing-values","dir":"Articles","previous_headings":"Some explanatory plots","what":"Missing values","title":"Data Exploration SES - 2014","text":"Check missing value 2018-individuals Let’s look closer variables missing values: Percentage missing values per columns missing values! Nothing bad, missing values seem occur column interested .","code":"# build dataset to check for missing values dataPlot <- melt(data_2014[, .(.id, is.na(.SD)), .SDcol = -c(   \".id\",   \"divenumber\",   \"divetype\",   \"date\" )]) # add the id of rows dataPlot[, id_row := c(1:.N), by = c(\"variable\", \".id\")]  # plot ggplot(dataPlot, aes(x = variable, y = id_row, fill = value)) +   geom_tile() +   labs(x = \"Attributes\", y = \"Rows\") +   scale_fill_manual(     values = c(\"white\", \"black\"),     labels = c(\"Real\", \"Missing\")   ) +   facet_wrap(.id ~ ., scales = \"free_y\") +   theme_jjo() +   theme(     legend.position = \"top\",     axis.text.x = element_text(angle = 45, hjust = 1),     legend.key = element_rect(colour = \"black\")   ) # table with percent table_inter <- data_2014[, lapply(.SD, function(x) {   round(length(x[is.na(x)]) * 100 / length(x), 1) }), .SDcol = -c(   \".id\",   \"divenumber\",   \"divetype\",   \"date\" )]  # find which are different from 0 cond_inter <- sapply(table_inter, function(x) {   x == 0 })  # display the percentages that are over 0 table_inter[, which(cond_inter) := NULL] %>%   sable(caption = \"Percentage of missing values per columns having missing values!\") %>%   scroll_box(width = \"100%\")"},{"path":"sesjo.github.io/ontodive/articles/data_exploration_ses_2014.html","id":"outliers","dir":"Articles","previous_headings":"Some explanatory plots","what":"Outliers","title":"Data Exploration SES - 2014","text":"Let’s see outliers. quiet easy spot looking distribution dive duration: Distribution dduration, maxdepth driftrate seal Nothing obvious, great :)","code":"# plot ggplot(   melt(data_2014,     id.vars = c(\".id\"),     measure.vars = c(\"dduration\", \"maxdepth\", \"driftrate\")   ),   aes(x = value, fill = .id) ) +   geom_histogram(show.legend = FALSE) +   scale_x_continuous(n.breaks = 3) +   facet_grid2(variable ~ .id,     scales = \"free\",     independent = \"x\",     labeller = labeller(.id = function(x) {       sub(         \"ind_\",         \"\",         unique(x)       )     })   ) +   labs(y = \"# of dives\") +   theme_jjo()"},{"path":"sesjo.github.io/ontodive/articles/data_exploration_ses_2014.html","id":"all-variables","dir":"Articles","previous_headings":"Some explanatory plots","what":"All Variables","title":"Data Exploration SES - 2014","text":"","code":"names_display <- names(data_2014[, -c(   \".id\",   \"date\",   \"divenumber\",   \"lightatsurf\",   \"divetype\",   \"day_departure\",   \"phase\",   \"lat\",   \"lon\",   \"sp\" )])  # calulate the median of driftrate for each day median_driftrate <- data_2014[divetype == \"2: drift\",   .(driftrate = quantile(driftrate, 0.5)),   by = .(date = as.Date(date), .id) ]  # let's identity when the smooth changes sign changes_driftrate <- median_driftrate %>%   .[, .(     y_smooth = predict(loess(driftrate ~ as.numeric(date), span = 0.25)),     date   ), by = .id] %>%   .[c(FALSE, diff(sign(y_smooth)) != 0), ]"},{"path":"sesjo.github.io/ontodive/articles/data_exploration_ses_2014.html","id":"full-trip-duration","dir":"Articles","previous_headings":"Some explanatory plots > All Variables","what":"Full trip duration","title":"Data Exploration SES - 2014","text":"vertical dashed lines represent changes buoyancy (see vignette(\"buoyancy_detect\") information)","code":"for (i in names_display) {   cat(\"#####\", i, \"{.unlisted .unnumbered} \\n\")   if (i == \"driftrate\") {     print(       ggplot(         data = melt(data_2014[, .(.id, date, get(i), divetype)],           id.vars = c(\".id\", \"date\", \"divetype\")         ),         aes(           x = as.Date(date),           y = value,           col = divetype         )       ) +         geom_point(           alpha = 1 / 10,           size = .5         ) +         geom_vline(           data = changes_driftrate,           aes(xintercept = date),           linetype = 2         ) +         facet_wrap(. ~ .id, scales = \"free\") +         scale_x_date(date_labels = \"%m/%Y\") +         labs(x = \"Date\", y = \"Drift Rate m/s\", col = \"Dive Type\") +         theme_jjo() +         theme(           axis.text.x = element_text(angle = 45, hjust = 1),           legend.position = \"bottom\"         ) +         guides(colour = guide_legend(override.aes = list(           size = 7,           alpha = 1         )))     )   } else {     print(       ggplot(         data = melt(data_2014[, .(.id, date, get(i))],           id.vars = c(\".id\", \"date\")         ),         aes(           x = as.Date(date),           y = value,           col = .id         )       ) +         geom_point(           show.legend = FALSE,           alpha = 1 / 10,           size = .5         ) +         geom_vline(           data = changes_driftrate,           aes(xintercept = date),           linetype = 2         ) +         facet_wrap(. ~ .id, scales = \"free\") +         scale_x_date(date_labels = \"%m/%Y\") +         labs(x = \"Date\", y = i) +         theme_jjo() +         theme(axis.text.x = element_text(angle = 45, hjust = 1))     )   }    cat(\"\\n \\n\") }"},{"path":"sesjo.github.io/ontodive/articles/data_exploration_ses_2014.html","id":"section","dir":"Articles","previous_headings":"","what":"Data Exploration SES - 2014","title":"Data Exploration SES - 2014","text":"maxdepth dduration botttime desctime descrate asctime ascrate pdi dwigglesdesc dwigglesbott dwigglesasc totvertdistbot driftrate dist_dep ssh psu vel temp bathy","code":""},{"path":"sesjo.github.io/ontodive/articles/data_exploration_ses_2014.html","id":"first-month-at-sea","dir":"Articles","previous_headings":"Some explanatory plots > All Variables","what":"First month at sea","title":"Data Exploration SES - 2014","text":"","code":"for (i in names_display) {   # subtitle   cat(\"#####\", i, \"{.unlisted .unnumbered} \\n\")    # print plot   print(     ggplot(       data = melt(         data_2014[           day_departure < 32,           .(.id, day_departure, get(i))         ],         id.vars = c(\".id\", \"day_departure\")       ),       aes(         x = day_departure,         y = value,         color = .id,         group = day_departure       )     ) +       geom_boxplot(         show.legend = FALSE,         alpha = 1 / 10,         size = .5       ) +       facet_wrap(. ~ .id, scales = \"free\") +       labs(x = \"# days since departure\", y = i) +       theme_jjo()   )   cat(\"\\n \\n\") }"},{"path":"sesjo.github.io/ontodive/articles/data_exploration_ses_2014.html","id":"section-1","dir":"Articles","previous_headings":"","what":"Data Exploration SES - 2014","title":"Data Exploration SES - 2014","text":"maxdepth dduration botttime desctime descrate asctime ascrate pdi dwigglesdesc dwigglesbott dwigglesasc totvertdistbot driftrate dist_dep ssh psu vel temp bathy","code":""},{"path":"sesjo.github.io/ontodive/articles/data_exploration_ses_2014.html","id":"dive-type","dir":"Articles","previous_headings":"","what":"Dive Type","title":"Data Exploration SES - 2014","text":"Evolution dive type proportion","code":"# dataset to plot proportional area plot dataPlot <- data_2014 %>%   .[, .(sum_id_days = .N), by = .(.id, day_departure, divetype)] %>%   .[, prop := sum_id_days / sum(sum_id_days), by = .(.id, day_departure)]  # area plot ggplot(dataPlot, aes(   x = as.numeric(day_departure),   y = prop,   fill = as.character(divetype) )) +   geom_area(alpha = 0.6, size = 1, position = \"stack\", stat = \"identity\") +   facet_wrap(.id ~ ., scales = \"free\") +   scale_y_continuous(labels = scales::percent) +   theme_jjo() +   theme(legend.position = \"bottom\") +   labs(     x = \"# of days since departure\",     y = \"Proportion of dives\",     fill = \"Dive types\"   )"},{"path":"sesjo.github.io/ontodive/articles/data_exploration_ses_2014.html","id":"drift-rate","dir":"Articles","previous_headings":"","what":"Drift Rate","title":"Data Exploration SES - 2014","text":"following graphs: driftrate calculated using divetype == \"2: drift\" whereas others variables calculated dives considered Dives driftrate > 0 excluded Drift rate vs. Bottom time Drift rate vs. Maximum depth Drift rate vs. Dive duration","code":"# build dataset dataPlot <- data_2014[   divetype == \"2: drift\" &     driftrate < 0,   # median drift rate for drift dive   .(driftrate = median(driftrate, na.rm = T)),   by = .(.id, day_departure) ] %>%   # merge to get other parameters including all dives   .[     data_2014[driftrate < 0,       .(         # median dive duration all dives considered         dduration = median(dduration, na.rm = T),         # median max depth all dives considered         maxdepth = median(maxdepth, na.rm = T),         # median bottom dives all dives considered         botttime = median(botttime, na.rm = T)       ),       by = .(.id, day_departure)     ],     on = c(\".id\", \"day_departure\")   ] # plot ggplot(dataPlot, aes(x = botttime, y = driftrate, col = .id)) +   geom_point(size = .5, alpha = .5) +   geom_smooth(method = \"lm\") +   guides(color = \"none\") +   facet_wrap(.id ~ .) +   scale_x_continuous(limits = c(0, 700)) +   labs(     x = \"Daily median Bottom time (s)\",     y = \"Daily median drift rate (m.s-1)\"   ) +   theme_jjo() # plot ggplot(dataPlot, aes(x = maxdepth, y = driftrate, col = .id)) +   geom_point(size = .5, alpha = .5) +   geom_smooth(method = \"lm\") +   guides(color = \"none\") +   scale_y_reverse() +   facet_wrap(.id ~ .) +   labs(     x = \"Daily median Maximum depth (m)\",     y = \"Daily median drift rate (m.s-1)\"   ) +   theme_jjo() # plot ggplot(dataPlot, aes(x = dduration, y = driftrate, col = .id)) +   geom_point(size = .5, alpha = .5) +   geom_smooth(method = \"lm\") +   guides(color = \"none\") +   facet_wrap(.id ~ .) +   labs(     x = \"Daily median Dive duration (s)\",     y = \"Daily median drift rate (m.s-1)\"   ) +   theme_jjo()"},{"path":"sesjo.github.io/ontodive/articles/data_exploration_ses_2014.html","id":"behavioral-aerobic-dive-limit-badl","dir":"Articles","previous_headings":"","what":"Behavioral Aerobic Dive Limit (bADL)","title":"Data Exploration SES - 2014","text":"Based Shero et al. (2018), decided look bADL 95th percentile dive duration day, \\(n \\geq 8\\). threshold chosen following figure, please note number particularly low cause one dive every 2.2 hours sampled: Distribution number dives day. threshold used calculate bADL fixed 50 dives per day. Behavioral ADL vs. drift rate along animals’ trip (one seeing kind relationship?) Looking graph, want believe kind relationship bADL defined Shero et al. (2018) drift rate (buyoancy).","code":"ggplot(   data_2014[, .(nb_dives = .N),     by = .(.id, day_departure)   ],   aes(x = nb_dives, fill = .id) ) +   geom_histogram(show.legend = FALSE) +   facet_wrap(. ~ .id) +   labs(y = \"# of days\", x = \"# of dives per day\") +   theme_jjo() +   theme(text = element_text(size = 8)) # select day that have at least 50 dives days_to_keep <- data_2014[,   .(nb_dives = .N),   by = .(.id, day_departure) ] %>%   .[nb_dives >= 8, ]  # keep only those days data_2014_complete_day <- merge(data_2014,   days_to_keep,   by = c(\".id\", \"day_departure\") )  # data plot dataPlot <- data_2014_complete_day[divetype == \"1: foraging\",   .(badl = quantile(dduration, 0.95)),   by = .(.id, day_departure) ]  # combine two datasets to be able to use a second axis # https://stackoverflow.com/questions/49185583/two-y-axes-with-different-scales-for-two-datasets-in-ggplot2 dataMegaPlot <- rbind(   data_2014_complete_day[divetype == \"2: drift\"] %>%     .[, .(       w = .id,       y = driftrate,       x = day_departure,       z = \"second_plot\"     )],   dataPlot[, .(     w = .id,     # tricky one     y = (badl / 1000) - 1,     x = day_departure,     z = \"first_plot\"   )] )  # plot ggplot() +   geom_point(     data = dataMegaPlot[z == \"second_plot\", ],     aes(x = x, y = y),     alpha = 1 / 10,     size = 0.5,     color = \"grey40\",     show.legend = FALSE   ) +   geom_path(     data = dataMegaPlot[z == \"first_plot\", ],     aes(x = x, y = y, color = w),     show.legend = FALSE   ) +   scale_y_continuous(     # Features of the first axis     name = \"Drift rate (m/s)\",     # Add a second axis and specify its features     sec.axis = sec_axis(~ (. * 1000) + 1000,       name = \"Behavioral Aerobic Dive Limit (s)\"     )   ) +   labs(x = \"# days since departure\") +   facet_wrap(w ~ .) +   theme_jjo() # get badl dataplot_1 <- data_2014_complete_day[,   .(badl = quantile(dduration, 0.95)),   by = .(.id, day_departure) ] # get driftrate dataplot_2 <- data_2014_complete_day[divetype == \"2: drift\",   .(driftrate = median(driftrate)),   by = .(.id, day_departure) ]  # merge dataPlot <- merge(dataplot_1,   dataplot_2,   by = c(\".id\", \"day_departure\"),   all = TRUE )  # plot ggplot(   data = dataPlot[driftrate < 0, ],   aes(x = badl, y = driftrate, col = .id) ) +   geom_point(show.legend = FALSE) +   geom_smooth(method = \"lm\", show.legend = FALSE) +   facet_wrap(.id ~ ., scales = \"free\") +   labs(     x = \"Behavioral Aerobic Dive Limit (s)\",     y = \"Drift rate (m/s)\"   ) +   theme_jjo()"},{"path":"sesjo.github.io/ontodive/articles/figures.html","id":"import-data","dir":"Articles","previous_headings":"","what":"Import Data","title":"Figures","text":"","code":"# load wealingNES package library(ontodive)  # load dataset data_nes <- get_data(\"nes\") data_ses <- get_data(\"ses\")  # merge into one dataset data_comp <- rbind(   rbindlist(data_nes$year_2018),   rbindlist(data_ses$year_2014),   use.names = T,   fill = T )  # remove outlier (i.e. dive duration > 5000 s) data_comp <- data_comp[dduration < 5000, ] data_comp[, diff_days := c(0, diff(day_departure)), by = .id]  # keep the first trip data_comp_split <- split(data_comp, by = c(\".id\")) data_comp_split_list <- lapply(data_comp_split, function(x) {   # find the rows after 100 day_departure where diff_days > 1   second_trip <- x[day_departure > 100 & diff_days > 1, ]   # if there is a second trip   if (nrow(second_trip) != 0) {     # get the first date of this second trip     date_cut <- second_trip[, min(date)]     # return only the first trip     return(x[date < date_cut, ])     # if no second trip   } else {     # return the full dataset     return(x)   } })  # rebuilt the dataset data_comp <- rbindlist(data_comp_split_list)  # rename sp for viz purposes data_comp %>% .[, sp_rename := fifelse(   sp == \"nes\",   \"Northern elephant seal\",   \"Southern elephant seal\" )] # rename divetype for viz purposes data_comp[, divetype_rename := divetype %>%   word(2) %>%   str_to_title()] data_comp[divetype_rename == \"Foraging\",           divetype_rename := \"Active Bottom\"]  # set up colours # https://davidmathlogic.com/colorblind/#%23D81B60-%231E88E5-%23FFC107-%23004D40 # https://thenode.biologists.com/data-visualization-with-flying-colors/research/ # https://color.adobe.com/create/color-accessibility # colours <- c(\"#e08214\", \"#8073ac\") colours <- c(\"#E1BE6A\", \"#009E73\")"},{"path":[]},{"path":"sesjo.github.io/ontodive/articles/figures.html","id":"figure-1","dir":"Articles","previous_headings":"2 Figures","what":"Figure 1","title":"Figures","text":"Figure 2.1: Illustrative data one representative weanling northern elephant seal (id: 2018070) one southern elephant seal (id: 130072) comparison. panels show two representative seals: () migration routes first trip sea Año Nuevo, California, United States America, Kerguelen Island, France, respectively gold green; (B) summary tag setup dive characteristics; development (C) maximum diving depth, (D) dive duration, (E) daily median drift rate. Data show clear improvement diving metrics species, northern elephant seals exhibiting accelerated development diving duration depth.","code":"# datasets data_fig_sum <- data_comp[!is.na(lat) & .id %in% c(   \"ind_2018070\",   \"ind_140072\" ), ] %>%   .[.id == \"ind_2018070\", .id := \"Northern elephant seal: ID 2018070\"] %>%   .[.id == \"ind_140072\", .id := \"Southern elephant seal: ID 140072\"] %>%   .[, .id := ordered(.id, levels = c(     \"Northern elephant seal: ID 2018070\",     \"Southern elephant seal: ID 140072\"   ))]  # maxdepth data_fig_sum_maxdepth <- melt(   data_fig_sum[, .(     date,     maxdepth,     day_departure,     .id   )],   id.vars = c(\"date\", \"day_departure\", \".id\"),   measure.vars = c(\"maxdepth\") )  # duration data_fig_sum_dduration <- melt(   data_fig_sum[, .(     date,     dduration,     day_departure,     .id   )],   id.vars = c(\"date\", \"day_departure\", \".id\"),   measure.vars = c(\"dduration\") )  # driftrate data_fig_sum_driftrate <- melt(   data_fig_sum[divetype == \"2: drift\", .(     driftrate = median(driftrate, na.rm = T),     day_departure = first(day_departure)   ),   by = .(date = as.Date(date), .id)   ],   id.vars = c(\"date\", \"day_departure\", \".id\"),   measure.vars = c(\"driftrate\") )  # bADL data_fig_sum_adl <- melt(   data_fig_sum[divetype == \"1: foraging\",     .(       adl = round(quantile(dduration, 0.95) /         60),       day_departure = first(day_departure)     ),     by = .(date = as.Date(date), .id)   ],   id.vars = c(\"date\", \"day_departure\", \".id\"),   measure.vars = c(\"adl\") )  # configure theme (to get gradient https://encycolorpedia.com/) nes_theme <- ttheme(   colnames.style = colnames_style(     color = \"black\",     fill = colours[1],     face = \"bold\"   ),   tbody.style = tbody_style(color = \"black\", fill = c(\"#e8c883\", \"#f3deb4\")) ) ses_theme <- ttheme(   colnames.style = colnames_style(     color = \"black\",     fill = colours[2],     face = \"bold\"   ),   tbody.style = tbody_style(color = \"black\", fill = c(\"#74bfa0\", \"#bbdfce\")) ) # map trip <- basemap(   shapefiles = \"DecimalDegree\",   bathymetry = TRUE ) +   geom_path(     data = data_fig_sum,     aes(x = lon, y = lat, group = .id),     linewidth = 2,     colour = \"white\",     show.legend = F   ) +   scale_fill_manual(     name = \"Bathymetry (m)\",     values = colorRampPalette(c(       \"#F7FBFF\", \"#DEEBF7\", \"#9ECAE1\", \"#4292C6\", \"#08306B\"     ))(10),     labels =       c(         \"0-50\",         \"50-300\",         \"300-500\",         \"500-1000\",         \"1000-1500\",         \"1500-2000\",         \"2000-4000\",         \"4000-6000\",         \"6000-10000\",         \">10000\"       )   ) +   geom_path(     data = data_fig_sum,     aes(x = lon, y = lat, col = .id),     linewidth = 1.5,     show.legend = F   ) +   scale_color_manual(values = colours, guide = \"none\") +   # annotation_raster(nes_image, -175, -145, 20, 50) +   # annotation_raster(ses_image, 75, 105, -50, -20) +   theme_void() +   theme(legend.position = \"top\")  # maxdepth fig_sum_maxdepth <-   ggplot(data_fig_sum_maxdepth, aes(x = day_departure, y = value, col = .id)) +   geom_point(     show.legend = F,     shape = 16,     size = 1,     alpha = 0.5   ) +   labs(y = \"Maximum depth (m)\") +   scale_y_reverse() +   scale_colour_manual(values = colours) +   facet_grid2(. ~ .id,     strip = strip_themed(background_x = elem_list_rect(fill = colours))   ) +   theme_jjo() +   theme(     axis.title.x = element_blank(),     axis.text.x = element_blank(),     axis.ticks.x = element_blank(),     strip.background = element_blank(),     strip.text.x = element_blank()   )  # driftrate fig_sum_dduration <-   ggplot(     data_fig_sum_dduration,     aes(x = day_departure, y = value / 60, col = .id)   ) +   geom_point(     show.legend = F,     shape = 16,     size = 1,     alpha = 0.5   ) +   labs(y = \"Dive duration (min)\") +   scale_colour_manual(values = colours) +   facet_grid2(. ~ .id,     strip = strip_themed(background_x = elem_list_rect(fill = colours))   ) +   theme_jjo() +   theme(     axis.title.x = element_blank(),     axis.text.x = element_blank(),     axis.ticks.x = element_blank(),     strip.background = element_blank(),     strip.text.x = element_blank()   )  # driftrate fig_sum_driftrate <-   ggplot(     data_fig_sum_driftrate,     aes(x = day_departure, y = value, col = .id)   ) +   geom_point(show.legend = F) +   geom_hline(     yintercept = 0,     linetype = \"dashed\",     size = 1   ) +   labs(     y = expression(paste(\"Daily median drift rate (m.\", s^-1, \")\")),     x = \"Number of days since departure\"   ) +   scale_colour_manual(values = colours) +   facet_grid2(. ~ .id,     strip = strip_themed(background_x = elem_list_rect(fill = colours))   ) +   theme_jjo() +   theme(     strip.background = element_blank(),     strip.text.x = element_blank()   ) # summary table for nes table_sum_nes <- data.table::transpose(data_fig_sum[sp == \"nes\", .(   \"# of days recorded\" = prettyNum(     uniqueN(as.Date(date)),     big.mark = \",\",     scientific = FALSE   ),   \"Recorder settings\" = \"All dives\",   \"# of dives recorded\" = prettyNum(.N, big.mark = \",\", scientific = FALSE),   \"Median max depth\" = paste(prettyNum(     round(quantile(maxdepth, 0.5), 1),     big.mark = \",\",     scientific = FALSE   ), \"m\"),   \"Median dive duration\" = paste(prettyNum(     round(quantile(dduration, 0.5) / 60, 1),     big.mark = \",\",     scientific = FALSE   ), \"min\") ), by = .(\"Seal ID\" = .id)], keep.names = \" \", make.names = 1)  # summary table for ses table_sum_ses <- data.table::transpose(data_fig_sum[sp == \"ses\", .(   \"# of days recorded\" = prettyNum(     uniqueN(as.Date(date)),     big.mark = \",\",     scientific = FALSE   ),   \"Recorder settings\" = \"1 dive every ~2.25 h\",   \"# of dives recorded\" = prettyNum(.N, big.mark = \",\", scientific = FALSE),   \"Median max depth\" = paste(prettyNum(     round(quantile(maxdepth, 0.5), 1),     big.mark = \",\",     scientific = FALSE   ), \"m\"),   \"Median dive duration\" = paste(prettyNum(     round(quantile(dduration, 0.5) / 60, 1),     big.mark = \",\",     scientific = FALSE   ), \"min\") ), by = .(\"Seal ID\" = .id)], keep.names = \" \", make.names = 1)  # format tables table_sum_nes <- tableGrob(table_sum_nes,   rows = NULL,   cols = NULL,   theme = nes_theme ) header_sum_nes <- tableGrob(mtcars[1, 1],   rows = NULL,   cols = c(data_fig_sum[sp == \"nes\", unique(.id)]),   theme = nes_theme ) table_sum_nes <- gtable_combine(header_sum_nes[1, ], table_sum_nes, along = 2) table_sum_nes$layout[1:2, c(\"r\")] <- 2 table_sum_nes$widths <- unit(c(0.6, 0.4), \"npc\")  table_sum_ses <- tableGrob(table_sum_ses,   rows = NULL,   cols = NULL,   theme = ses_theme ) header_sum_ses <- tableGrob(mtcars[1, 1],   rows = NULL,   cols = c(data_fig_sum[sp == \"ses\", unique(.id)]),   theme = ses_theme ) table_sum_ses <- gtable_combine(header_sum_ses[1, ], table_sum_ses, along = 2) table_sum_ses$layout[1:2, c(\"r\")] <- 2 table_sum_ses$widths <- unit(c(0.6, 0.4), \"npc\") layout <- \" AAAADDD AAAADDD AAAADDD AAAADDD AAAADDD AAAADDD AAAAEEE AAAAEEE AAAAEEE AAAAEEE AAAAEEE BBBBEEE BBBBFFF CCCCFFF CCCCFFF CCCCFFF CCCCFFF CCCCFFF \"  # plot_to_save <- trip +   guide_area() +   (as_ggplot(table_sum_nes) + as_ggplot(table_sum_ses)) +   fig_sum_maxdepth +   fig_sum_dduration +   fig_sum_driftrate +   plot_annotation(tag_levels = list(c(\"(A)\", \"(B)\", \"\", \"(C)\", \"(D)\", \"(E)\"))) +   # layout   plot_layout(design = layout, guides = \"collect\") &   # annotation in bold   theme(plot.tag = element_text(face = \"bold\")) # export (height 785; width 1494) # ggsave(\"test.png\", width = 180, height = 90, units = \"mm\", dpi = 300, scale = 2.5) # save the plot # ggsave(\"figure_1.png\", #        plot_to_save, #        width = 180, #        height = 90, #        units = \"mm\", #        dpi = 300, #        scale = 2.5)"},{"path":"sesjo.github.io/ontodive/articles/figures.html","id":"figure-2","dir":"Articles","previous_headings":"2 Figures","what":"Figure 2","title":"Figures","text":"Figure 2.2: Development depth duration across dive types throughout first trip sea northern (n = 4) southern elephant seals (n = 9) estimated generalized additive models. solid lines represent means, shaded areas represent 95% confidence intervals. Marginal density plots represent spread data across dive types species.","code":"# initial plots fig_maxdepth_ini <- plot_comp(   data_comp,   \"maxdepth\",   group_to_compare = \"sp_rename\",   nb_days = 200,   cols = \"divetype_rename\",   ribbon = T,   point = F,   colours = colours,   linetype_ribbon = 0,   individual = FALSE,   # method = \"GCV.Cp\",   scales = \"free_y\" ) fig_dduration_ini <- plot_comp(   copy(data_comp)[, dduration_min := dduration / 60],   \"dduration_min\",   group_to_compare = \"sp_rename\",   nb_days = 200,   cols = \"divetype_rename\",   ribbon = T,   point = F,   colours = colours,   linetype_ribbon = 0,   individual = FALSE,   # method = \"GCV.Cp\",   scales = \"free_y\" ) # get limits maxdepth_limits <- ggplot_build(fig_maxdepth_ini)$layout$panel_params[[1]]$y.range dduration_limits <- ggplot_build(fig_dduration_ini)$layout$panel_params[[1]]$y.range  # update initial plots fig_maxdepth <- fig_maxdepth_ini +   labs(     y = \"Maximum depth (m)\",     colour = \"Elephant seals\",     fill = \"Elephant seals\"   ) +   coord_cartesian(ylim = rev(maxdepth_limits)) +   scale_colour_manual(     values = colours,     labels = data_comp[, sort(unique(sp_rename))] %>%       word(1) %>%       str_to_title()   ) +   scale_fill_manual(     values = colours,     labels = data_comp[, sort(unique(sp_rename))] %>%       word(1) %>%       str_to_title()   ) +   theme_jjo() +   theme(     legend.position = \"top\",     axis.title.x = element_blank(),     axis.text.x = element_blank(),     axis.line.x = element_blank(),     axis.ticks.x = element_blank(),     strip.text = element_text(colour = \"grey20\"),     axis.line.y = element_line(color = \"black\")   ) fig_dduration <- fig_dduration_ini +   labs(     x = \"Number of days since departure\",     y = \"Dive duration (min)\"   ) +   coord_cartesian(ylim = dduration_limits) +   theme_jjo() +   theme(     legend.position = \"none\",     strip.text.x = element_blank(),     axis.line.y = element_line(color = \"black\")   )  # density plots fig_dens_maxdepth <-   ggplot(data_comp[day_departure <= 200, ], aes(y = maxdepth, fill = sp)) +   geom_density(show.legend = F, col = \"black\", alpha = 0.4, size = 0.3) +   coord_cartesian(ylim = rev(maxdepth_limits)) +   scale_fill_manual(values = colours) +   theme_void() fig_dens_dduration <-   ggplot(data_comp[day_departure <= 200, ], aes(y = dduration / 60, fill = sp)) +   geom_density(show.legend = F, col = \"black\", alpha = 0.4, size = 0.3) +   coord_cartesian(ylim = dduration_limits) +   scale_fill_manual(values = colours) +   theme_void() # plot_to_save <- ((fig_maxdepth | fig_dens_maxdepth) + plot_layout(ncol = 2, widths = c(5, 1))) /   ((fig_dduration | fig_dens_dduration) + plot_layout(ncol = 2, widths = c(5, 1))) # # save the plot # ggsave(filename = \"figure_2.png\", #        plot = plot_to_save, #        width = 9, #        height = 6) # Mann Whitney / Wilcoxon rank sum test on dive depth tidy(wilcox.test(   data_comp[day_departure <= 200 & sp == \"nes\", maxdepth],   data_comp[day_departure <= 200 & sp == \"ses\", maxdepth] )) %>%   gt() %>%   tab_header(title = \"Mann Whitney / Wilcoxon rank sum test on dive depth\") # Mann Whitney / Wilcoxon rank sum test on dive duration tidy(wilcox.test(   data_comp[day_departure <= 200 & sp == \"nes\", dduration],   data_comp[day_departure <= 200 & sp == \"ses\", dduration] )) %>%   gt() %>%   tab_header(title = \"Mann Whitney / Wilcoxon rank sum test on dive duration\")"},{"path":"sesjo.github.io/ontodive/articles/figures.html","id":"figure-3","dir":"Articles","previous_headings":"2 Figures","what":"Figure 3","title":"Figures","text":"Figure 2.3: Frequency dive types across time day species. Species-wide statistical tests based averages individual’s dive type proportion weighted total number dives. Percentages middle panel represent frequency dive type across species time day. Asterisks (*) indicate significant difference (P-value < 0.0001) day-time night-time dive proportions within species (two-sample z-test).","code":"# (only for .id with location data, and so phase information) prop_dive_id_phase_divetype_sp <- data_comp[   !is.na(lat),   table(divetype_rename, sp, sp_rename, phase, .id) ] %>%   # the calculate the proportion of dive in each divetype, per sp and phases   prop.table(., c(\".id\")) %>%   # convert into a data.table   as.data.table(.)  # merge this table to add the number of dives, per divetype, phase, sp, .id prop_dive_id_phase_divetype_sp <-   merge(     prop_dive_id_phase_divetype_sp,     data_comp[!is.na(lat),       .(nb_dives_divetype = uniqueN(divenumber)),       by = .(sp, sp_rename, .id, divetype_rename, phase)     ] %>%       .[, nb_dives := sum(nb_dives_divetype),         by = .(.id)       ] %>%       .[],     by = c(\"sp_rename\", \"sp\", \".id\", \"divetype_rename\", \"phase\"),     all.y = T   )  # calculate the right proportions dataPlot <- prop_dive_id_phase_divetype_sp %>%   .[, .(     N = wtd.mean(N, nb_dives),     # its equivalent of using only the number of dives and not the percentage     # N == N_v2     N_v2 = sum(nb_dives_divetype) / sum(nb_dives),     N_sd = sqrt(wtd.var(N, nb_dives))   ),   by = .(sp_rename, sp, divetype_rename, phase)   ] # p_value calculation for nes df_p_val_nes <- data_comp[sp == \"nes\" & !is.na(lat),   .(nb_divetype = .N),   by = .(divetype_rename, phase) ] %>%   .[, nb_dive := sum(nb_divetype)] %>%   # perform by divetype   rstatix::group_by(divetype_rename) %>%   # a prop.test test   summarise(rstatix::prop_test(x = nb_divetype, n = nb_dive, correct = F)) %>%   # then adjust the p_value for multiple test   rstatix::adjust_pvalue(p.col = \"p\", method = \"bonferroni\") %>%   # update p.adj   rstatix::add_significance(p.col = \"p.adj\") %>%   # sort   arrange(divetype_rename)  # dataset for nes dataPlot_nes <- copy(dataPlot)[sp == \"nes\", N := -(1 * N)] %>%   .[sp == \"nes\"]  # plot fig_nes_prop <-   ggplot(     dataPlot_nes,     aes(x = divetype_rename, y = N, fill = phase)   ) +   geom_bar(     stat = \"identity\",     position = \"dodge\",     color = \"grey30\"   ) +   scale_y_continuous(     labels = function(x) {       percent(abs(x), 1)     }   ) +   geom_errorbar(aes(ymin = N - N_sd, ymax = N),     width = .2,     position = position_dodge(.9)   ) +   coord_flip(ylim = c(-c(round((dataPlot[, max(N + N_sd)] + 0.03) * 100) / 100, 0))) +   facet_grid(. ~ sp_rename, scales = \"free_x\") +   theme_jjo() +   # day first, and night   scale_fill_manual(     values = c(\"white\", \"grey\"),     labels = c(\"Day-time\", \"Night-time\")   ) +   # add stat   geom_signif(     y_position = dataPlot_nes[, .(position = min(N - N_sd)), divetype_rename]$position +       dataPlot_nes[, max(N + N_sd)] * 0.5,     xmin = seq(0, dataPlot_nes[, uniqueN(divetype_rename)] - 1) + 0.8,     xmax = seq(1, dataPlot_nes[, uniqueN(divetype_rename)]) + 0.2,     # replace **** by *** (more standard)     annotation = fifelse(       df_p_val_nes$p.adj.signif == \"****\",       \"***\",       df_p_val_nes$p.adj.signif     ),     tip_length = 0,     vjust = -0.6,     angle = 90   ) +   labs(fill = \"Time of day\") +   theme(     legend.position = \"top\",     axis.line.y = element_blank(),     axis.title.y = element_blank(),     axis.title.x = element_blank(),     axis.text.y = element_blank(),     axis.ticks.y = element_blank(),     axis.line = element_line(arrow = arrow(       length = unit(0.2, \"lines\"),       type = \"closed\",       ends = \"first\"     )),     strip.background = element_rect(fill = colours[1]),     strip.text = element_text(colour = \"grey20\")   )  # p_value calculation for ses df_p_val_ses <- data_comp[sp == \"ses\" & !is.na(lat),   .(nb_divetype = .N),   by = .(divetype_rename, phase) ] %>%   .[, nb_dive := sum(nb_divetype)] %>%   # perform by divetype   rstatix::group_by(divetype_rename) %>%   # a prop.test test   summarise(rstatix::prop_test(x = nb_divetype, n = nb_dive, correct = F)) %>%   # then adjust the p_value for multiple test   rstatix::adjust_pvalue(p.col = \"p\", method = \"bonferroni\") %>%   # update p.adj   rstatix::add_significance(p.col = \"p.adj\") %>%   # sort   arrange(divetype_rename)  # dataset for ses dataPlot_ses <- copy(dataPlot)[sp == \"ses\", ] %>%   .[sp == \"ses\"]  # plot fig_ses_prop <-   ggplot(dataPlot_ses, aes(x = divetype_rename, y = N, fill = phase)) +   geom_bar(     stat = \"identity\",     position = \"dodge\",     color = \"grey30\"   ) +   scale_y_continuous(     labels = function(x) {       percent(abs(x), 1)     }   ) +   geom_errorbar(aes(ymin = N, ymax = N + N_sd),     width = .2,     position = position_dodge(.9)   ) +   coord_flip(ylim = c(0, round((dataPlot[, max(N + N_sd)] + 0.03) * 100) / 100)) +   facet_grid(. ~ sp_rename, scales = \"free_x\") +   theme_jjo() +   # day first, and night   scale_fill_manual(     values = c(\"white\", \"grey\"),     labels = c(\"Day-time\", \"Night-time\")   ) +   # add stat   geom_signif(     y_position = dataPlot_ses[, .(position = max(N + N_sd)), divetype_rename]$position +       dataPlot_ses[, min(N + N_sd)] * 0.5,     xmin = seq(0, dataPlot_ses[, uniqueN(divetype_rename)] - 1) + 0.8,     xmax = seq(1, dataPlot_ses[, uniqueN(divetype_rename)]) + 0.2,     # replace **** by *** (more standard)     annotation = fifelse(       df_p_val_ses$p.adj.signif == \"****\",       \"***\",       df_p_val_ses$p.adj.signif     ),     tip_length = 0   ) +   labs(fill = \"Time of day\") +   theme(     legend.position = \"none\",     axis.line.y = element_blank(),     axis.title.y = element_blank(),     axis.title.x = element_blank(),     axis.text.y = element_blank(),     axis.ticks.y = element_blank(),     axis.line.x = element_line(arrow = arrow(       length = unit(0.2, \"lines\"), type = \"closed\"     )),     strip.background = element_rect(fill = colours[2]),     strip.text = element_text(colour = \"grey20\")   )  df_text <- data.table(   x = rep(0, data_comp[, uniqueN(divetype_rename)]),   label_to_order = data_comp[, sort(unique(divetype_rename))],   divetype = copy(data_comp)[divetype_rename == \"Active Bottom\",                              divetype_rename := \"Active Btt.\"] %>%      .[, sort(unique(divetype_rename))],   percentage = round(as.vector(prop.table(data_comp[     !is.na(lat),     table(divetype_rename)   ])) * 100, 1) ) %>%   .[, label_to_display := paste0(divetype, \"\\n(\", percentage, \" %)\")] fig_text <-   ggplot(df_text, aes(x = x, y = label_to_order, label = label_to_display)) +   geom_text() +   theme_void()  fig_label_1 <-   ggplot(data.frame(l = \"Percentage of dives\", x = 1, y = 1)) +   geom_text(aes(x, y, label = l)) +   theme_void() +   coord_cartesian(clip = \"off\") ((fig_nes_prop | fig_text | fig_ses_prop) +   plot_layout(     widths = c(7, 2, 7),     guides = \"collect\"   ) &   theme(legend.position = \"top\")) / fig_label_1 +   plot_layout(heights = c(6, 1))"},{"path":"sesjo.github.io/ontodive/articles/figures.html","id":"figure-4","dir":"Articles","previous_headings":"2 Figures","what":"Figure 4","title":"Figures","text":"Figure 2.4: Changes median drift rate across first trip sea northern (n = 4) southern (n = 9) elephant seals estimated generalized additive model. bold solid lines represent mean species-level responses thin lines represent individual-level responses. shaded areas represent 95% confidence interval, black dashed line indicates neutral buoyancy. Marginal density plots indicate data spread across entire migration species.","code":"# calculate the median of driftrate for each day median_driftrate <- data_comp[divetype == \"2: drift\",   .(driftrate = quantile(driftrate, 0.5)),   by = .(day_departure, .id, sp) ] %>%   .[, sp := fifelse(sp == \"nes\", \"Northern\", \"Southern\")]  # initial plots fig_driftrate_ini <- plot_comp(   median_driftrate,   \"driftrate\",   group_to_compare = \"sp\",   nb_days = 200,   ribbon = T,   linetype_ribbon = 0,   point = F,   colours = colours ) # get limits driftrate_limits <- ggplot_build(fig_driftrate_ini)$layout$panel_params[[1]]$y.range  # update initial plots fig_driftrate <- fig_driftrate_ini +   labs(     y = expression(paste(\"Daily median drift rate (m.\", s^-1, \")\")),     x = \"Number of days since departure\",     colour = \"Elephant seal\",     fill = \"Elephant seal\"   ) +   geom_hline(     yintercept = 0,     linetype = 2,     size = 1,     col = \"black\"   ) +   coord_cartesian(ylim = driftrate_limits) +   theme_jjo() +   theme(     legend.position = \"top\"   )  # density plots fig_dens_driftrate <-   ggplot(     data_comp[divetype == \"2: drift\" & day_departure <= 200, ],     aes(y = driftrate, fill = sp)   ) +   geom_density(show.legend = F, col = \"black\", alpha = 0.4, size = 0.3) +   coord_cartesian(ylim = driftrate_limits) +   scale_fill_manual(values = colours) +   theme_void() (fig_driftrate | fig_dens_driftrate) + plot_layout(widths = c(5, 1))"},{"path":"sesjo.github.io/ontodive/articles/figures.html","id":"appendix","dir":"Articles","previous_headings":"2 Figures","what":"Appendix","title":"Figures","text":"Figure 2.5: Development depth throughout first trip sea northern (n = 4) southern elephant seals (n = 9) estimated generalized additive models. solid lines represent means, shaded areas represent 95% confidence intervals. Marginal density plots represent spread data species. Depth 260 meters reached 30 days northern elephant seals 160 southern elephant seals. Figure 2.6: Development dive duration throughout first trip sea northern (n = 4) southern elephant seals (n = 9) estimated generalized additive models. solid lines represent means, shaded areas represent 95% confidence intervals. Marginal density plots represent spread data species. Dive duration 11.15 min reached first day northern elephant seals’ trip sea 125 days southern elephant seals.","code":"# initial plots max_depth_all_res <- plot_comp(   data_comp %>%     .[, sp := fifelse(sp == \"nes\", \"Northern\", \"Southern\")],   \"maxdepth\",   group_to_compare = \"sp\",   nb_days = 200,   ribbon = T,   linetype_ribbon = 0,   point = F,   colours = colours,   export_data_model = T ) max_depth_all_ini <- max_depth_all_res[[1]] max_depth_all_data <- max_depth_all_res[[2]] # https://stackoverflow.com/questions/70420256/how-to-draw-a-horizontal-line-and-a-vertical-line-that-cross-at-the-intersection draw_guides <- function(x, y) {   list(     geom_segment(aes(x = -Inf, xend = x, y = y, yend = y), linetype = \"dashed\"),     geom_segment(aes(x = x, xend = x, y = y, yend = -Inf), linetype = \"dashed\")   ) } # get limits max_depth_all_limits <- ggplot_build(max_depth_all_ini)$layout$panel_params[[1]]$y.range  # update initial plots max_depth_all <- max_depth_all_ini +   labs(     y = \"Maximum depth (m)\",     x = \"Number of days since departure\",     colour = \"Elephant seal\",     fill = \"Elephant seal\"   ) +   coord_cartesian(ylim = rev(max_depth_all_limits)) +   scale_fill_manual(values = colours) +   geom_point(data = data.table(x = c(30, 160), y = c(240, 240)), aes(x, y)) +   apply(data.table(x = c(30, 160), y = c(240, 240)), 1, function(dt) {     draw_guides(dt[1], dt[2])   }) +   scale_x_continuous(position = \"top\") +   theme_jjo() +   theme(     legend.position = \"bottom\",     axis.line.y = element_line(color = \"black\", arrow = arrow(       length = unit(0.2, \"lines\"),       type = \"closed\",       ends = \"first\"     )),   )  # density plots fig_dens_max_depth_all <-   ggplot(     data_comp[day_departure <= 200, ],     aes(y = maxdepth, fill = sp)   ) +   geom_density(show.legend = F, col = \"black\", alpha = 0.4, linewidth = 0.3) +   coord_cartesian(ylim = rev(max_depth_all_limits)) +   scale_fill_manual(values = colours) +   theme_void() # plot # plot_to_save <- (max_depth_all | fig_dens_max_depth_all) + plot_layout(widths = c(5, 1)) # # to save # ggsave(\"figure_supp_1.png\", #   plot_to_save, #   width = 6, #   height = 4 # ) # initial plots dive_duration_all_res <- plot_comp(   copy(data_comp)[, dduration := dduration / 60],   \"dduration\",   group_to_compare = \"sp\",   nb_days = 200,   ribbon = T,   linetype_ribbon = 0,   point = F,   colours = colours,   export_data_model = T ) dive_duration_all_ini <- dive_duration_all_res[[1]] dive_duration_all_data <- dive_duration_all_res[[2]] # get limits dive_duration_all_limits <- ggplot_build(dive_duration_all_ini)$layout$panel_params[[1]]$y.range  # update initial plots dive_duration_all <- dive_duration_all_ini +   labs(     y = \"Dive duration (min)\",     x = \"Number of days since departure\",     colour = \"Elephant seal\",     fill = \"Elephant seal\"   ) +   geom_point(data = data.table(x = c(0, 125), y = c(11.15, 11.15)), aes(x, y)) +   apply(data.table(x = c(0, 125), y = c(11.15, 11.15)), 1, function(dt) {     draw_guides(dt[1], dt[2])   }) +   coord_cartesian(ylim = dive_duration_all_limits) +   scale_fill_manual(values = colours) +   theme_jjo() +   theme(     legend.position = \"top\"   )  # density plots fig_dens_dive_duration_all <-   ggplot(     data_comp[day_departure <= 200, ],     aes(y = dduration / 60, fill = sp)   ) +   geom_density(show.legend = F, col = \"black\", alpha = 0.4, linewidth = 0.3) +   coord_cartesian(ylim = dive_duration_all_limits) +   scale_fill_manual(values = colours) +   theme_void() # # plot # plot_to_save <- (dive_duration_all | fig_dens_dive_duration_all) +   plot_layout(widths = c(5, 1)) # # to save # ggsave(\"figure_supp_2.png\", #        plot_to_save, #        width = 6, #        height = 4)"},{"path":[]},{"path":"sesjo.github.io/ontodive/articles/figures.html","id":"table-1","dir":"Articles","previous_headings":"3 Tables","what":"Table 1","title":"Figures","text":"thought table provides summary information gives rapid overview dataset. Title: Descriptive statistics visual representations dataset’s first offshore foraging trip northern southern elephant seal. maximum depth (m; note inverted y-axis) dive duration (min), trend represents changes daily 95th percentile time (solid gray line) associated linear regression (black dashes). drift rate (m.s-1), daily median calculated represent evolution time, positive values orange negative violet. measurements length mass made weaning.","code":"# based on # https://themockup.blog/posts/2020-10-31-embedding-custom-features-in-gt-tables/ gt_ggplot_driftrate <- function(table_data, plot_col, data_col, plot_fun, ...) {   # save the data extract ahead of time   # to be used in our anonymous function below   data_in <- purrr::pluck(table_data, \"_data\", data_col)    # retrieve min max   range_x <- rbindlist(data_in)[, range(day_departure)]   range_y <- c(-0.35, 0.15)    # draw plot   text_transform(     table_data,     # note the use of {{}} here - this is tidy eval     # that allows you to indicate specific columns     locations = cells_body(columns = c({{ plot_col }})),     fn = function(x) {       # build the plot       plot <- lapply(data_in, function(x) {         # build the plot         ggplot(x) +           # for color https://davidmathlogic.com/colorblind/#%23D81B60-%231E88E5-%23FFC107-%23004D40           geom_area(             aes(x = day_departure, y = ifelse(driftrate < 0,               driftrate, 0             )),             fill = \"#5D3A9B\", alpha = 0.5           ) +           # for color https://davidmathlogic.com/colorblind/#%23D81B60-%231E88E5-%23FFC107-%23004D40           geom_area(             aes(x = day_departure, y = ifelse(driftrate > 0,               driftrate, 0             )),             fill = \"#E66100\", alpha = 0.5           ) +           geom_segment(             aes(               x = 0,               y = 0,               xend = max(day_departure) + 10,               yend = 0             ),             size = 7,             colour = \"grey30\",             arrow = arrow(               type = \"closed\",               length = unit(0.2, units = \"npc\")             )           ) +           coord_cartesian(xlim = range_x, ylim = range_y) +           theme_void() +           theme(             panel.grid = element_blank(),             panel.border = element_blank(),           )       })        # draw for every row       lapply(plot, ggplot_image, aspect_ratio = 5, height = 25)     }   ) } gt_ggplot_sparkline <- function(table_data, plot_col, data_col, plot_fun, ...) {   # save the data extract ahead of time   # to be used in our anonymous function below   data_in <- purrr::pluck(table_data, \"_data\", data_col)    # colnames   col_names <- colnames(rbindlist(data_in))    # interest variable   var_interest <- setdiff(col_names, \"day_departure\")    # retrieve min max   range_x <- rbindlist(data_in)[, range(day_departure)]   range_y <- rbindlist(data_in)[, range(get(var_interest))]    # draw plot   text_transform(     table_data,     # note the use of {{}} here - this is tidy eval     # that allows you to indicate specific columns     locations = cells_body(columns = c({{ plot_col }})),     fn = function(x) {       # build the plot       plot <- lapply(data_in, function(x) {         # build the plot         ggplot(x, aes(x = day_departure, y = get(var_interest))) +           geom_path(size = 6, color = \"grey60\") +           geom_smooth(             size = 10,             linetype = \"dashed\",             colour = \"black\",             method = \"lm\",             se = FALSE,             na.rm = TRUE           ) +           coord_cartesian(xlim = range_x, ylim = range_y) +           theme_void() +           theme(             panel.grid = element_blank(),             panel.border = element_blank()           )       })        # draw for every row       lapply(plot, ggplot_image, aspect_ratio = 4, height = 26)     }   ) } # summary_table_es <- data_comp[, travel_distance := distGeo(   matrix(c(lon, lat), ncol = 2),   matrix(c(shift(lon), shift(lat)), ncol = 2) ), by = .id ] %>%   as_tibble() %>%   mutate(id_rename = word(.id, 2, sep = \"_\")) %>%   group_by(sp_rename, id_rename) %>%   summarise(     N = prettyNum(n(),       big.mark = \",\",       scientific = FALSE     ),     nb_days = round(as.numeric(difftime(       last(date), first(date),       units = \"days\"     )), 1),     travel_distance = prettyNum(       sum(travel_distance, na.rm = T) / 1000,       digits = 1,       big.mark = \",\",       scientific = FALSE     ),     Maxdepth_mean = round(mean(maxdepth), 1),     Maxdepth_plus_minus = \"±\",     Maxdepth_sd = round(sd(maxdepth), 1),     Dduration_mean = round(mean(dduration) / 60, 1),     Dduration_plus_minus = \"±\",     Dduration_sd = round(sd(maxdepth) / 60, 1),     .groups = \"drop\"   ) %>%   # replace travel_distance = 0 by NA   mutate(travel_distance = na_if(travel_distance, \"0\")) %>%   # add driftrate from drift dives   left_join(     .,     data_comp %>%       as_tibble() %>%       mutate(id_rename = word(.id, 2, sep = \"_\")) %>%       group_by(sp_rename, id_rename, day_departure) %>%       filter(divetype == \"2: drift\") %>%       summarise(         driftrate = as.numeric(quantile(           driftrate, 0.5,           na.rm = T         )),         .groups = \"drop\"       ) %>%       group_by(sp_rename, id_rename) %>%       summarise(         sparkline_driftrate = list(           data.frame(             driftrate = driftrate,             day_departure = day_departure           )         ),         .groups = \"drop\"       ),     by = c(\"sp_rename\", \"id_rename\")   ) %>%   # add quantile 95 of dduration and max_depth   left_join(     .,     data_comp %>%       as_tibble() %>%       mutate(id_rename = word(.id, 2, sep = \"_\")) %>%       group_by(sp_rename, id_rename, day_departure) %>%       summarise(         maxdepth = as.numeric(quantile(maxdepth, 0.95, na.rm = T)),         dduration = as.numeric(quantile(dduration, 0.95, na.rm = T)),         .groups = \"drop\"       ) %>%       group_by(sp_rename, id_rename) %>%       summarise(         sparkline_qt_dduration = list(           data.frame(             dduration = dduration,             day_departure = day_departure           )         ),         sparkline_qt_maxdepth = list(           data.frame(             maxdepth = -maxdepth,             day_departure = day_departure           )         ),         .groups = \"drop\"       ),     by = c(\"sp_rename\", \"id_rename\")   ) %>%   # add percentage   left_join(     .,     data_comp %>%       as_tibble() %>%       mutate(id_rename = word(.id, 2, sep = \"_\")) %>%       group_by(sp_rename, id_rename, divetype) %>%       summarise(         n = n(),         .groups = \"drop\"       ) %>%       group_by(sp_rename, id_rename) %>%       mutate(         divetype_perc = round(n * 100 / sum(n)),         divetype,         .groups = \"drop\"       ) %>%       arrange(divetype) %>%       group_by(sp_rename, id_rename) %>%       summarise(divetype_perc = list(divetype_perc), .groups = \"drop\"),     by = c(\"sp_rename\", \"id_rename\")   ) %>%   # add wean mass based on Weanling Dive Metada.xlsx   left_join(     .,     data.table(       id_rename = c(         \"2018070\",         \"2018072\",         \"2018074\",         \"2018080\",         \"140059\",         \"140060\",         \"140062\",         \"140063\",         \"140068\",         \"140069\",         \"140072\",         \"140073\",         \"140075\"       ),       sp_rename = c(         rep(\"Northern elephant seal\", 4),         rep(\"Southern elephant seal\", 9)       ),       weanmass = c(132, 138, 119, 142, 118, 112, 85, NA, 125, NA, NA, 102, NA)     ),     by = c(\"sp_rename\", \"id_rename\")   ) %>%   # add wean length based on JoffreyMeasurements 2023_02_01.xlsx and   # metadata_pups20142015.xlsx   left_join(     .,     data.table(       id_rename = c(         \"2018070\",         \"2018072\",         \"2018074\",         \"2018080\",         \"140059\",         \"140060\",         \"140062\",         \"140063\",         \"140068\",         \"140069\",         \"140072\",         \"140073\",         \"140075\"       ),       sp_rename = c(         rep(\"Northern elephant seal\", 4),         rep(\"Southern elephant seal\", 9)       ),       lenmass = c(144, NA, 131, 142, 141, 141, 118, NA, 136, NA, NA, 134, NA)     ),     by = c(\"sp_rename\", \"id_rename\")   ) %>%   # reorder column   relocate(nb_days, N, travel_distance, weanmass, lenmass, divetype_perc,     .after = id_rename   ) %>%   # setup group row   gt(groupname_col = \"sp_rename\") %>%   # spanner (several columns into one column)   tab_spanner(     label = \"Maximum depth (m)\",     columns = c(       Maxdepth_mean,       Maxdepth_plus_minus,       Maxdepth_sd,       sparkline_qt_maxdepth     )   ) %>%   tab_spanner(     label = \"Dive duration (min)\",     columns = c(       Dduration_mean,       Dduration_plus_minus,       Dduration_sd,       sparkline_qt_dduration     )   ) %>%   tab_spanner(     label = md(\"Daily median drift rate\"),     columns = c(sparkline_driftrate)   ) %>%   tab_spanner(     label = md(\"Travel distance\"),     columns = c(travel_distance)   ) %>%   tab_spanner(     label = md(\"Mass\"),     columns = c(weanmass)   ) %>%   tab_spanner(     label = md(\"Length\"),     columns = c(lenmass)   ) %>%   tab_spanner(     label = md(\"Dive type proportions\"),     columns = c(divetype_perc)   ) %>%   # plot   gt_ggplot_sparkline(sparkline_qt_maxdepth, \"sparkline_qt_maxdepth\") %>%   gt_ggplot_sparkline(sparkline_qt_dduration, \"sparkline_qt_dduration\") %>%   gt_ggplot_driftrate(sparkline_driftrate, \"sparkline_driftrate\") %>%   gt_plt_bar_stack_extra(     divetype_perc,     width = 65,     labels = c(\"Transit\", \"Active Btt.\", \"Drift\", \"Benthic\"),     palette = c(\"#000000\", \"#444444\", \"#888888\", \"#CCCCCC\")   ) %>%   # alignement   cols_align(     columns = c(N, Maxdepth_sd, Dduration_sd),     align = \"left\"   ) %>%   cols_align(     columns = c(N, Maxdepth_mean, Dduration_mean),     align = \"right\"   ) %>%   cols_align(     columns = c(travel_distance, weanmass, lenmass, Maxdepth_plus_minus, Dduration_plus_minus),     align = \"center\"   ) %>%   # format   fmt_number(     columns = Maxdepth_mean,     decimal = 1   ) %>%   fmt_number(     columns = ends_with(\"_sd\"),     decimal = 1   ) %>%   # rename columns   cols_label(     N = \"# dives\",     id_rename = md(\"ID\"),     nb_days = \"# days\",     travel_distance = \"(km)\",     weanmass = \"(kg)\",     lenmass = \"(cm)\",     Maxdepth_mean = md(\"Mean\"),     Maxdepth_plus_minus = md(\"±\"),     Maxdepth_sd = md(\"SD\"),     sparkline_qt_maxdepth = md(\"Trend\"),     Dduration_mean = md(\"Mean\"),     Dduration_plus_minus = md(\"±\"),     Dduration_sd = md(\"SD\"),     sparkline_driftrate = md(\"(m.s<sup>-1<\/sup>)\"),     sparkline_qt_dduration = md(\"Trend\")   ) %>%   # add color square   text_transform(     locations = cells_row_groups(),     fn = function(x) {       # identify sp       sp <- unique(x)       # set colour       colour <-         if_else(grepl(\"Northern\", sp), colours[1], colours[2])       # html to add the color box       purrr::map(x, ~ html(         glue(           \"<div><span style='height: 15px;width: 15px;background-color: {colour};display: inline-block;border-radius:5px;float:left;top:13%;left:5%;'<\/span> <span style='display: inline-block;float:left;line-height:20px;padding: 0px 25px;white-space:nowrap;'>{sp}<\/span><\/div>\"         )       ))     }   ) %>%   # color cols   gt_highlight_cols(     columns = c(       Maxdepth_mean,       Maxdepth_plus_minus,       Maxdepth_sd,       sparkline_qt_maxdepth,       sparkline_driftrate,       weanmass,       N     ),     fill = \"lightgrey\",     alpha = 0.5   ) %>%   # footnote   tab_footnote(     footnote = \"Recorded\",     locations = cells_column_labels(columns = c(N, nb_days))   ) %>%   # color rows   opt_row_striping() %>%   # set horizontal padding for plus minus   tab_style(     style = \"padding-left:0px;padding-right:0px;\",     locations = cells_column_labels(columns = ends_with(\"plus_minus\"))   ) %>%   tab_style(     style = \"padding-left:0px;padding-right:0px;\",     locations = cells_body(columns = ends_with(\"plus_minus\"))   ) %>%   # set horizontal padding for plus minus   tab_style(     style = \"padding-top:0px;padding-bottom:0px\",     locations = cells_body(columns = starts_with(\"sparkline\"))   ) %>%   # settings   tab_options(     # # width table     table.width = pct(180),     # table.width = pct(150),     # padding = vertical space between rows     data_row.padding = px(3),     # horizontal scroll     container.overflow.x = T   ) # # for export # summary_table_es %>% gtsave_extra( #   \"test_table_1.png\", #   vwidth = 2000, #   vheight = 580, #   # cliprect = \"viewport\" # )"},{"path":"sesjo.github.io/ontodive/articles/figures.html","id":"extra","dir":"Articles","previous_headings":"3 Tables","what":"Extra","title":"Figures","text":"","code":"# by species data_comp %>%   .[!is.na(lat), `:=`(     sunrise_today = maptools::sunriset(matrix(c(lon, lat), ncol = 2),       date,       direction = \"sunrise\",       POSIXct.out = TRUE     )$time,     sunset_today = maptools::sunriset(matrix(c(lon, lat), ncol = 2),       date,       direction = \"sunset\",       POSIXct.out = TRUE     )$time   ), ] %>%   # calculation day-time length   .[, day_time := as.numeric(difftime(sunset_today,     sunrise_today,     units = \"hours\"   ))] %>%   # calculation night-time length   .[, night_time := 24 - day_time] %>%   # calculate maxdepth and dduration   .[, .(     result_depth = paste(       round(mean(maxdepth), 1),       \"±\",       round(sd(maxdepth), 1)     ),     result_duration = paste(       round(mean(dduration / 60), 1),       \"±\",       round(sd(dduration / 60), 1)     ),     result_day_time = paste(       round(mean(day_time, na.rm = T), 1),       \"±\",       round(sd(day_time, na.rm = T), 1)     ),     result_night_time = paste(       round(mean(night_time, na.rm = T), 1),       \"±\",       round(sd(night_time, na.rm = T), 1)     )   ), by = .(sp_rename)] %>%   # add wean mass based on Weanling Dive Metada.xlsx   merge(., data.table(     id_rename = c(       \"2018070\",       \"2018072\",       \"2018074\",       \"2018080\",       \"140059\",       \"140060\",       \"140062\",       \"140063\",       \"140068\",       \"140069\",       \"140072\",       \"140073\",       \"140075\"     ),     sp_rename = c(       rep(\"Northern elephant seal\", 4),       rep(\"Southern elephant seal\", 9)     ),     weanmass = c(132, 138, 119, 142, 118, 112, 85, NA, 125, NA, NA, 102, NA)   ) %>%     .[, .(result_mass = paste(       round(mean(weanmass, na.rm = T), 1),       \"±\",       round(sd(weanmass, na.rm = T), 1)     )),     by = sp_rename     ],   by = \"sp_rename\"   ) %>%   merge(., data.table(     id_rename = c(       \"2018070\",       \"2018072\",       \"2018074\",       \"2018080\",       \"140059\",       \"140060\",       \"140062\",       \"140063\",       \"140068\",       \"140069\",       \"140072\",       \"140073\",       \"140075\"     ),     sp_rename = c(       rep(\"Northern elephant seal\", 4),       rep(\"Southern elephant seal\", 9)     ),     lenmass = c(144, NA, 131, 142, 141, 141, 118, NA, 136, NA, NA, 134, NA)   ) %>%     .[, .(result_len = paste(       round(mean(lenmass, na.rm = T), 1),       \"±\",       round(sd(lenmass, na.rm = T), 1)     )),     by = sp_rename     ],   by = \"sp_rename\"   ) %>%   merge(., data_comp[, .(travel_distance = sum(travel_distance, na.rm = T) / 1000),     by = .(.id, sp_rename)   ] %>%     .[, travel_distance := na_if(travel_distance, 0)] %>%     .[, .(result_distance = paste(round(mean(       travel_distance,       na.rm = T     ), 1), \"±\", round(sd(       travel_distance,       na.rm = T     ), 1))), by = .(sp_rename)], by = \"sp_rename\") %>%   merge(., data_comp[, .(nb_days = as.numeric(difftime(max(date),     min(date),     units = \"day\"   ))),   by = .(.id, sp_rename)   ] %>%     .[, .(nb_days = paste(       round(mean(nb_days, na.rm = T), 1),       \"±\",       round(sd(nb_days, na.rm = T), 1)     )),     by = .(sp_rename)     ], by = \"sp_rename\") %>%   gt() %>%   tab_spanner(     label = md(\"Dive\"),     columns = c(\"result_depth\", \"result_duration\")   ) %>%   tab_spanner(     label = md(\"Length (days)\"),     columns = c(\"result_day_time\", \"result_night_time\")   ) %>%   tab_spanner(     label = md(\"Weaning\"),     columns = c(\"result_mass\", \"result_len\")   ) %>%   tab_spanner(     label = md(\"Travel\"),     columns = c(\"result_distance\")   ) %>%   cols_label(     sp_rename = \"Species\",     result_depth = \"Depth (m)\",     result_duration = \"Duration (days)\",     result_day_time = \"Day\",     result_night_time = \"Night\",     result_mass = \"Mass (kg)\",     result_len = \"Length (cm)\",     result_distance = \"Distance (km)\"   ) %>%   opt_row_striping() %>%   # settings   tab_options(     # # width table     table.width = pct(175),     # table.width = pct(150),     # padding = vertical space between rows     data_row.padding = px(3),     # horizontal scroll     container.overflow.x = T   )"},{"path":"sesjo.github.io/ontodive/articles/netcdf_read.html","id":"whats-a-netcdf-file","dir":"Articles","previous_headings":"","what":"What’s a netCDF file?","title":"netCDF 101","text":"NetCDF (Network Common Data Form) set software libraries self-describing, machine-independent data formats support creation, access, sharing array-oriented scientific data. project homepage1 hosted Unidata program University Corporation Atmospheric Research (UCAR). also chief source netCDF software, standards development, updates, etc. format open standard. NetCDF Classic 64-bit Offset Format international standard Open Geospatial Consortium.2 – Wikipedia way see netCDF file ’s matrix usually contains environmental data across time location, plus extra information (called metadata) dataset comes , resolution.","code":""},{"path":"sesjo.github.io/ontodive/articles/netcdf_read.html","id":"how-to-open-it","dir":"Articles","previous_headings":"","what":"How to open it?","title":"netCDF 101","text":"Super simple, using tidync package! Let’s say netcdf file called global-reanalysis-phy-001-031-grepv2-daily_1639765258612.nc, import file: First 10 rows flatten netCDF file Now can see time proper format. first thing look metadata see find kind explanation. , ’re going use ncmeta package, developped purpose. column time seems number days since 1950-01-01. Let’s use information format time column proper way. First 10 rows flatten netCDF file, reformat time column","code":"# first load `tidync` package library(tidync)  # then import your file df_nc <- tidync(\"../inst/extdata/copernicus/global-reanalysis-phy-001-031-grepv2-daily_1639765258612.nc\")  # flatten the multidimensional array df <- df_nc %>%   # extract NetCDF data as an expanded table   hyper_tibble() %>%   # not mandatory, but here is the code to convert to a data.table   setDT() # print the first 10 rows df[sample(nrow(df), 10), ] %>%   sable(     caption = \"First 10 rows of the flatten netCDF file\",     digits = 2   ) # load ncmeta library library(ncmeta)  # then we use the function nc_atts to access attributes of times print(   nc_atts(     \"../inst/extdata/copernicus/global-reanalysis-phy-001-031-grepv2-daily_1639765258612.nc\",     \"time\"   ) %>%     # we want information on the unit for time column     dplyr::filter(name == \"units\") %>%     pull(value) ) ## $units ## [1] \"days since 1950-01-01 00:00:00\" # convert time into a readable format df[, time := as.Date(time, origin = as.Date(\"1950-01-01\"))]  # print df[sample(nrow(df), 10), ] %>%   sable(     caption = \"First 10 rows of the flatten netCDF file, with reformat time column\",     digits = 2   )"},{"path":"sesjo.github.io/ontodive/articles/netcdf_read.html","id":"how-to-visualize-it","dir":"Articles","previous_headings":"","what":"How to visualize it?","title":"netCDF 101","text":"Well plenty ways display data within netCDF. , presenting one simple way using ggplot2 gganimate package. 4 models current velocity North-East part Pacific ocean Four different GIFs, since four different models get SST:","code":"# first let's calculate the velocity norm df[, `:=`(   vel_cglo = sqrt(uo_cglo^2 + vo_cglo^2),   vel_oras = sqrt(uo_oras^2 + vo_oras^2),   vel_foam = sqrt(uo_foam^2 + vo_foam^2),   vel_glor = sqrt(uo_glor^2 + vo_glor^2),   month = month(time),   year = year(time) )]  # average by month df_summarize <- df[, .(   vel_cglo = mean(vel_cglo, na.rm = T),   vel_oras = mean(vel_oras, na.rm = T),   vel_foam = mean(vel_foam, na.rm = T),   vel_glor = mean(vel_glor, na.rm = T) ), by = .(   date = paste(year, \"-\", month),   longitude,   latitude ) ] %>%   .[, time := .GRP, by = .(date)] # data wrangling dataPlot <- melt(df_summarize,   id.vars = c(\"date\", \"longitude\", \"latitude\", \"time\"),   variable.name = \"model\" )  # let's comput the ouput of all models res_anim <- ggplot() +   geom_raster(     data = dataPlot,     aes(x = longitude, y = latitude, fill = value),     interpolate = TRUE   ) +   geom_sf(     data = spData::world,     col = 1,     fill = \"ivory\"   ) +   coord_sf(xlim = c(-165, -115), ylim = c(25, 55)) +   facet_wrap(. ~ model, ncol = 2) +   theme_jjo() +   theme(legend.position = \"bottom\") +   labs(x = NULL, y = NULL) +   scale_fill_gradientn(colours = oce::oceColors9A(120)) +   labs(title = \"Date: {df_summarize[,unique(date)][frame_time]}\") +   transition_time(time) +   ease_aes(\"linear\") # let's print animate(res_anim, height = 500, width = 500)"},{"path":"sesjo.github.io/ontodive/articles/phase_of_the_day.html","id":"display-the-data-of-2018-individuals","dir":"Articles","previous_headings":"","what":"Display the data of 2018-individuals","title":"Detect phases of the day","text":"Let’s first load package data. visualize data, summarize point plot median light level one hour one day. Visualization light level surface along 2018-individuals’ trip much data missing value day time? Well, good news can clearly see pattern saw 2004023. Let’s look distribution Distribution lightatsurf threshold 110. bimodal distribution individual seems quite well separated threshold 110, correspond threshold used individual 2004023. 2018 individuals, 110 seems also appropriate value.","code":"# load library library(ontodive)  # load data data_nes <- get_data(\"nes\")  # combine all individuals data_2018 <- rbindlist(data_nes$year_2018, use.name = TRUE, idcol = TRUE)  # remove phase column for the purpose of this document data_2018[, phase := NULL] # let's first average `lightatsurf` by individuals, day since departure and hour dataPlot <- data_2018[, .(lightatsurf = median(lightatsurf, na.rm = T)),   by = .(.id, day_departure, date = as.Date(date), hour = hour(date)) ]  # display the result ggplot(dataPlot, aes(x = day_departure, y = hour, fill = lightatsurf)) +   geom_tile() +   facet_grid(.id ~ .) +   theme_jjo() +   labs(x = \"# of days since departure\", y = \"Hour\", fill = \"Light level at the surface\") +   theme(legend.position = c(\"bottom\")) # display the result ggplot(dataPlot, aes(x = lightatsurf, fill = .id)) +   geom_histogram(show.legend = FALSE) +   geom_vline(xintercept = 110, linetype = \"longdash\") +   facet_wrap(.id ~ .) +   theme_jjo()"},{"path":"sesjo.github.io/ontodive/articles/phase_of_the_day.html","id":"lets-give-a-try-to-the-findtwilights-function","dir":"Articles","previous_headings":"","what":"Let’s give a try to the findTwilights function","title":"Detect phases of the day","text":"Let’s first reshape data complied findTwilights function. Visualization light level surface along 2018-individuals’ trip, twilight detection points bad actually! many outliers need addressed. Let’s try keep pair Rise (TRUE, FALSE) longer period time day. Visualization light level surface along 2018-individuals’ trip, twilight detection points corrected ’s definitely better, remaining outliers (especially individual ind_2018074). Let’s zoom first days since departure individual, see ’s going . Visualization light level surface first 100 days ind_2018074, twilight detection points corrected can see, low light levels encountered middle daytime mislead findTwilight function finding sunrise sunset. Two ways explored deal outliers:","code":"# identification of sunset, sunrise pairs res_twi <- data_2018[!is.na(lightatsurf),   findTwilights(.(Date = date, Light = lightatsurf),     threshold = 110, include = date   ),   by = .id ]  # add `day_departure` to res_twi using a rolling join # https://www.r-bloggers.com/2016/06/understanding-data-table-rolling-joins/ res_twi <- data_2018[, .(.id, Twilight = date, day_departure)] %>%   .[res_twi, roll = T, on = c(\".id\", \"Twilight\")] %>%   # hour column   .[, hour := hour(Twilight)]  # display the result ggplot() +   geom_tile(data = dataPlot, aes(x = day_departure, y = hour, fill = lightatsurf)) +   geom_point(data = res_twi, aes(x = day_departure, y = hour, col = Rise)) +   facet_grid(.id ~ .) +   theme_jjo() +   labs(     x = \"# of days since departure\",     y = \"Hour\",     fill = \"Light level at the surface\",     col = \"Sunrise\"   ) +   theme(legend.position = c(\"bottom\")) # calculate the period of time between a sunrise and a sunset (i.e. two consecutive rows) res_twi[, period_time := c(0, as.numeric(diff(Twilight, units = \"hours\"),   units = \"mins\" )), by = .(.id, as.Date(Twilight)) ]  # keep only the longer period of time and the row just before res_twi_inter <- res_twi[   c(     # index of row with the longer period of time     res_twi[, .I[period_time == max(period_time)],       by = .(.id, as.Date(Twilight))     ]$V1,     # index of the row previous the one with the longer period of time     res_twi[, .I[period_time == max(period_time)],       by = .(.id, as.Date(Twilight))     ]$V1 - 1   ) ] %>%   # reorder by date   .[order(Twilight)] # display the result ggplot() +   geom_tile(data = dataPlot, aes(x = day_departure, y = hour, fill = lightatsurf)) +   geom_point(data = res_twi_inter, aes(x = day_departure, y = hour, col = Rise)) +   facet_grid(.id ~ .) +   theme_jjo() +   labs(     x = \"# of days since departure\",     y = \"Hour\",     fill = \"Light level at the surface\",     col = \"Sunrise\"   ) +   theme(legend.position = c(\"bottom\")) # display the result ggplot() +   geom_tile(     data = dataPlot[.id == \"ind_2018074\" & day_departure < 100, ],     aes(x = day_departure, y = hour, fill = lightatsurf)   ) +   geom_point(     data = res_twi_inter[.id == \"ind_2018074\" & day_departure < 100],     aes(x = day_departure, y = hour, col = Rise)   ) +   theme_jjo() +   labs(     x = \"# of days since departure\",     y = \"Hour\",     fill = \"Light level at the surface\",     col = \"Sunrise\"   ) +   theme(legend.position = c(\"top\"))"},{"path":"sesjo.github.io/ontodive/articles/phase_of_the_day.html","id":"section","dir":"Articles","previous_headings":"","what":"Detect phases of the day","title":"Detect phases of the day","text":"Adding condition distribution period_time Smoothing light level signal Since outliers observed Figure @ref(fig:zoom_2010074) daytime, means period_time longer usual days. Considering , impose condition variable make sure neither long either short. Distributions time difference two rows identified sunrise sunset Considering graph, let’s try keep rows period_time==0 300<period_time<900 Visualization light level surface along 2018-individuals’ trip, twilight detection points corrected work! several sunset sunrise identified within day, current algorithm calculates period_time two successive rows, whereas test every possible combination. Since points due outliers day, try smooth light level signal run findTwilight function . far, successful using method cause seems quite tricky smooth signal lot missing values.","code":"# display ggplot(res_twi_inter, aes(x = period_time, fill = .id)) +   geom_histogram() +   facet_grid(.id ~ .) +   theme_jjo() # remove outlier (but keep the 0) res_twi_out <- res_twi[period_time == 0 | period_time %between% c(300, 900)]  # keep only the longer period of time and the row just before res_twi_out_inter <- res_twi_out[   c(     # index of row with the longer period of time     res_twi_out[, .I[period_time == max(period_time)],       by = .(.id, as.Date(Twilight))     ]$V1,     # index of the row previous the one with the longer period of time     res_twi_out[, .I[period_time == max(period_time)],       by = .(.id, as.Date(Twilight))     ]$V1 - 1   )   # reorder by date ] %>%   # reorder by date   .[order(Twilight)] # display the result ggplot() +   geom_tile(data = dataPlot, aes(x = day_departure, y = hour, fill = lightatsurf)) +   geom_point(data = res_twi_out_inter, aes(x = day_departure, y = hour, col = Rise)) +   facet_grid(.id ~ .) +   theme_jjo() +   labs(     x = \"# of days since departure\",     y = \"Hour\",     fill = \"Light level at the surface\",     col = \"Sunrise\"   ) +   theme(legend.position = c(\"bottom\")) # # let's first split our dataset by individual # split_inter = split(data_2018, data_2018$.id) # # # create a times series of ligth level # split_inter = lapply(split_inter, function(x) { #   # summerize data at the min level #   df = x[,.(lightatsurf = median(lightatsurf, na.rm=T)), by=.(date = floor_date(date, unit=\"min\"))] #   # creation of a time series #   z = as.ts(zoo(df$lightatsurf, df$date)) #   # smoother creation #   # https://boostedml.com/2020/05/an-introduction-to-time-series-smoothing-in-r.html #   s = ksmooth(time(z),as.numeric(z),'normal',bandwidth=6) #   # retrieve smooth value #   x[, lightatsurf_smooth := s$y] # }) # # # unlist # data_2018 = rbindlist(split_inter)"},{"path":"sesjo.github.io/ontodive/articles/phase_of_the_day.html","id":"lets-try-a-clustering-method","dir":"Articles","previous_headings":"","what":"Let’s try a clustering method","title":"Detect phases of the day","text":"Since can visually see day night time, try clustering method.","code":""},{"path":"sesjo.github.io/ontodive/articles/phase_of_the_day.html","id":"k-means-hierarchical-clustering","dir":"Articles","previous_headings":"Let’s try a clustering method","what":"K-MEANS + Hierarchical clustering","title":"Detect phases of the day","text":"test package well-known perform clustering FactoMineR. idea behind main method performed hierarchical clustering initial centroids positioned based pre-performed k-means using first component PCA. information feel free look website. Visualization moment light measured surface colored associated cluster (HCPC) Well, clearly algorithm suited deal kind patterns!","code":"# remove nan value df_clust <- dataPlot[!is.na(lightatsurf), .(hour, day_departure, lightatsurf)]  # HCPC with onlys 2 groups res_hcpc <- FactoMineR::HCPC(df_clust, nb.clust = 2, graph = FALSE)  # display the result ggplot() +   geom_tile(     data = dataPlot[!is.na(lightatsurf), ] %>%       .[, cluster := res_hcpc$data.clust$clust],     aes(x = day_departure, y = hour, fill = factor(cluster))   ) +   theme_jjo() +   facet_grid(.id ~ .) +   labs(     x = \"# of days since departure\",     y = \"Hour\",     fill = \"cluster\",     col = \"Sunrise\"   ) +   theme(legend.position = c(\"bottom\"))"},{"path":"sesjo.github.io/ontodive/articles/phase_of_the_day.html","id":"dbscan","dir":"Articles","previous_headings":"Let’s try a clustering method","what":"DBSCAN","title":"Detect phases of the day","text":"DBSCAN seems elegant algorithm deal outliers non-convex cluster. issue choose right value two parameters: Reachability distance Reachability minimum number points might tricky! Visualization moment light measured surface colored associated cluster (DBSCAN, eps=45, MinPts=nrow(dataPlot)*0.06) Well ’s quite nice :) still outliers (especially individual ind_2018074) identify cluster 1 whereas like see cluster 2.","code":"# determine the right values by testing several of them... res_dbscan <- dbscan(df_clust,   eps = 21,   MinPts = nrow(dataPlot) * 0.01,   method = \"raw\" )  # display the result ggplot() +   geom_tile(     data = dataPlot[!is.na(lightatsurf), ][, cluster := res_dbscan$cluster],     aes(x = day_departure, y = hour, fill = factor(cluster))   ) +   theme_jjo() +   facet_grid(.id ~ .) +   labs(     x = \"# of days since departure\",     y = \"Hour\",     fill = \"cluster\",     col = \"Sunrise\"   ) +   theme(legend.position = c(\"bottom\"))"},{"path":"sesjo.github.io/ontodive/articles/phase_of_the_day.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Detect phases of the day","text":"now used result DBSCAN algorithm, since results seem better!","code":"# referential creation ref_phase_day <- dataPlot[!is.na(lightatsurf), ] %>%   .[, cluster := res_dbscan$cluster] %>%   .[, cluster := fifelse(cluster == 1, \"night\", \"day\")] %>%   .[]  # reshape ref_phase_day <- melt(ref_phase_day,   id.vars = c(\".id\", \"date\", \"hour\"),   measure.vars = \"cluster\",   value.name = \"phase\" )  # set date format ref_phase_day[, `:=`(   date = date + hours(hour),   hour = NULL,   variable = NULL )]  # rolling join data_2018 <- ref_phase_day[data_2018, roll = T, on = .(.id, date)]"},{"path":"sesjo.github.io/ontodive/articles/phase_of_the_day.html","id":"wip","dir":"Articles","previous_headings":"","what":"WIP","title":"Detect phases of the day","text":"also try define two phases day: sunset: plus minus 30 min transition night day sunrise: plus minus 30 min transition day night Problem, day times found several days, marked night!","code":"# identification of transition ref_phase_day[, transition := c(1, abs(diff(as.numeric(as.factor(phase)))))]  # keep only the first date and the last date (i.e transition) by date and individual ref_phase_day <- ref_phase_day[transition == 1, .SD[c(1, .N)], by = .(.id, date)]  # convert date to take into account hour ref_phase_day[, date := date + hours(hour)]  # add sunset test <- rbind(   ref_phase_day[, .SD, .SDcols = -c(\"transition\")] %>%     .[, date := date + minutes(30)],   ref_phase_day[, .SD, .SDcols = -c(\"transition\")] %>%     .[phase == \"night\", ] %>%     .[, `:=`(       date = date - minutes(30),       phase = \"sunset\"     )],   ref_phase_day[, .SD, .SDcols = -c(\"transition\")] %>%     .[phase == \"day\", ] %>%     .[, `:=`(       date = date - minutes(30),       phase = \"sunrise\"     )] )"},{"path":"sesjo.github.io/ontodive/articles/plot_presentation.html","id":"northern-elephant-seals","dir":"Articles","previous_headings":"","what":"Northern Elephant Seals","title":"Individuals Info","text":"ind_2018070 ind_2018072 ind_2018080","code":""},{"path":"sesjo.github.io/ontodive/articles/plot_presentation.html","id":"southern-elephant-seals","dir":"Articles","previous_headings":"","what":"Southern Elephant Seals","title":"Individuals Info","text":"ind_140059 ind_140060 ind_140062 ind_140063 ind_140068 ind_140069 ind_140072 ind_140073 ind_140075","code":""},{"path":[]},{"path":"sesjo.github.io/ontodive/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Joffrey Joumaa. Author, maintainer. Roxanne Beltran. Author, funder.","code":""},{"path":"sesjo.github.io/ontodive/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Joumaa J, Beltran R (2023). ontodive: Data Analyses Ontogeny Paper. R package version 0.1.0, https://github.com/sesjo/ontodive/.","code":"@Manual{,   title = {ontodive: Data Analyses of the Ontogeny Paper},   author = {Joffrey Joumaa and Roxanne Beltran},   year = {2023},   note = {R package version 0.1.0},   url = {https://github.com/sesjo/ontodive/}, }"},{"path":"sesjo.github.io/ontodive/index.html","id":"ontodive-","dir":"","previous_headings":"","what":"Data Analyses of the Ontogeny Paper","title":"Data Analyses of the Ontogeny Paper","text":"ontodive repository contains R package name includes analyses functions accompanying paper “Contrasting offspring dependence periods diving development rates two closely related marine mammal species” Joffrey Jouma’, Florian Orgeret, Baptiste Picard, Patrick W. Robinson, Henri Weimerskirch, Christophe Guinet, Daniel P. Costa, Roxanne S. Beltran.","code":""},{"path":"sesjo.github.io/ontodive/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Data Analyses of the Ontogeny Paper","text":"can install released version ontodive GitHub : may encounter error , case changing network solved problem others also reported.","code":"if (require(devtools)) {   devtools::install_github(repo = \"SESjo/ontodive\") } else {   install.packages(\"devtools\")   devtools::install_github(repo = \"SESjo/ontodive\") } # Downloading GitHub repo SESjo/ontodive@HEAD # Error in utils::download.file(url, path, method = method, quiet = quiet,  : #   download from 'https://api.github.com/repos/SESjo/ontodive/tarball/HEAD' failed"},{"path":"sesjo.github.io/ontodive/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Data Analyses of the Ontogeny Paper","text":"installed, can easily access vignettes (supposed associated specific analysis) using commands:","code":"# load the package library(ontodive)  # browse vignette browseVignettes(\"ontodive\")"},{"path":[]},{"path":"sesjo.github.io/ontodive/reference/build_github_vignette.html","id":null,"dir":"Reference","previous_headings":"","what":"Build Vignettes for Github — build_github_vignette","title":"Build Vignettes for Github — build_github_vignette","text":"function aims processing vignette (building, organizing) pushing Github user can download package pre-compiled vignette. Using website argument allow build associated website.","code":""},{"path":"sesjo.github.io/ontodive/reference/build_github_vignette.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build Vignettes for Github — build_github_vignette","text":"","code":"build_github_vignette(   article = NULL,   website = NULL,   vignette = NULL,   clean = FALSE )"},{"path":"sesjo.github.io/ontodive/reference/build_github_vignette.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build Vignettes for Github — build_github_vignette","text":"article name path .Rmd file compiled website boolean compile website associated article vignette boolean compile vignette associated article clean Logical remove cache temporary files","code":""},{"path":"sesjo.github.io/ontodive/reference/build_github_vignette.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build Vignettes for Github — build_github_vignette","text":"\\docs folder containing website inst\\doc folder containing vignette","code":""},{"path":"sesjo.github.io/ontodive/reference/build_github_vignette.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Build Vignettes for Github — build_github_vignette","text":"make sure pre-compiled vignette enclosed within package downloaded Github, vignette () compiled tools::buildVignettes, (ii) copy-paste inst\\doc. build website, function first converts README.Rmd file README.md file, calls pkgdown::build_site() since function take account *.md.","code":""},{"path":"sesjo.github.io/ontodive/reference/build_github_vignette.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Build Vignettes for Github — build_github_vignette","text":"https://community.rstudio.com/t/--add-article-html--r-files---github-rep/45905/7","code":""},{"path":"sesjo.github.io/ontodive/reference/build_github_vignette.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build Vignettes for Github — build_github_vignette","text":"","code":"if (FALSE) { # compile all articles into vignette and website build_github_vignette() }"},{"path":"sesjo.github.io/ontodive/reference/calc_phase_day.html","id":null,"dir":"Reference","previous_headings":"","what":"Determine the different phases of the day — calc_phase_day","title":"Determine the different phases of the day — calc_phase_day","text":"function can estimate day-time night-time based light level (dbscan) using location time data (noaa).","code":""},{"path":"sesjo.github.io/ontodive/reference/calc_phase_day.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Determine the different phases of the day — calc_phase_day","text":"","code":"calc_phase_day(   dataset,   light = \"lightatsurf\",   date = \"date\",   id = \".id\",   lon = \"lon\",   lat = \"lat\",   method = \"noaa\" )"},{"path":"sesjo.github.io/ontodive/reference/calc_phase_day.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Determine the different phases of the day — calc_phase_day","text":"dataset dataset containing light level per individual per time light Name light-level column date Name datetime column id Name individual ID column lon Name Longitude column lat Name Latitude column method Method used identify phases day (\"noaa\" \"dbscan\")","code":""},{"path":"sesjo.github.io/ontodive/reference/calc_phase_day.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Determine the different phases of the day — calc_phase_day","text":"Return data.table additional phase columns","code":""},{"path":"sesjo.github.io/ontodive/reference/calc_phase_day.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Determine the different phases of the day — calc_phase_day","text":"Methods: DBSCAN use dbscan clustering algorithm identify night time daytime. NOAA use algorithm provided National Oceanic & Atmospheric Administration (NOAA).","code":""},{"path":"sesjo.github.io/ontodive/reference/calc_phase_day.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Determine the different phases of the day — calc_phase_day","text":"vignette(\"phase_of_the_day\")","code":""},{"path":[]},{"path":"sesjo.github.io/ontodive/reference/calc_phase_day.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Determine the different phases of the day — calc_phase_day","text":"","code":"if (FALSE) { # load data data_nes <- get_data(\"nes\")  # night and day calculation result <- calc_phase_day(rbindlist(data_nes$year_2018,   use.name = TRUE,   idcol = TRUE )) }"},{"path":"sesjo.github.io/ontodive/reference/check_dt.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if an object is a data.table — check_dt","title":"Check if an object is a data.table — check_dt","text":"Allow quickly check object data.table","code":""},{"path":"sesjo.github.io/ontodive/reference/check_dt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if an object is a data.table — check_dt","text":"","code":"check_dt(dt)"},{"path":"sesjo.github.io/ontodive/reference/check_dt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if an object is a data.table — check_dt","text":"dt object check","code":""},{"path":"sesjo.github.io/ontodive/reference/check_dt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if an object is a data.table — check_dt","text":"boolean: * TRUE object data.table * FALSE object data.table","code":""},{"path":"sesjo.github.io/ontodive/reference/check_dt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check if an object is a data.table — check_dt","text":"function checks class data.table among considered object's classes.","code":""},{"path":"sesjo.github.io/ontodive/reference/check_dt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check if an object is a data.table — check_dt","text":"","code":"# load data.table library(data.table)  # data.table creation dt <- data.table()  # check if `dt` is a data.table check_dt(dt) #> [1] TRUE"},{"path":"sesjo.github.io/ontodive/reference/data_cop.html","id":null,"dir":"Reference","previous_headings":"","what":"Oceanographic information from North East Pacific and Southern Ocean — data_cop","title":"Oceanographic information from North East Pacific and Southern Ocean — data_cop","text":"dataset retrieved Copernicus using product GLOBAL_MULTIYEAR_PHY_001_030 dataset cmems_mod_glo_phy_my_0.083_P1D-m.","code":""},{"path":"sesjo.github.io/ontodive/reference/data_cop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Oceanographic information from North East Pacific and Southern Ocean — data_cop","text":"","code":"data(data_cop)"},{"path":"sesjo.github.io/ontodive/reference/data_cop.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Oceanographic information from North East Pacific and Southern Ocean — data_cop","text":"list two data tables, one northern elephant seals southern elephant seals, row correspond cell 0.083° × 0.083° specific time location. $northen: [lat=c(25, 55); lon=c(-165, -115); time c(\"2018-05-01\", \"2019-05-01\")] $southern: [lat=c(-65, -40); lon=c(35, 115); time c(\"2015-01-01\", \"2015-11-30\")] time date latitude latitude longitude longitude uo eastward ocean current velocity (m/s) vo northward ocean current velocity (m/s) salinity (psu) thetao potential temperature (°C) zos sea surface height geoid (m) vel ocean current velocity (m/s)","code":""},{"path":"sesjo.github.io/ontodive/reference/data_cop.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Oceanographic information from North East Pacific and Southern Ocean — data_cop","text":"https://resources.marine.copernicus.eu/product-detail/GLOBAL_MULTIYEAR_PHY_001_030/INFORMATION","code":""},{"path":"sesjo.github.io/ontodive/reference/data_nes.html","id":null,"dir":"Reference","previous_headings":"","what":"Diving parameters of weanling Northern Elephant Seals in 2016 and 2018 — data_nes","title":"Diving parameters of weanling Northern Elephant Seals in 2016 and 2018 — data_nes","text":"list datasets containing diving parameters : 4 individuals 2018","code":""},{"path":"sesjo.github.io/ontodive/reference/data_nes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Diving parameters of weanling Northern Elephant Seals in 2016 and 2018 — data_nes","text":"","code":"data(data_nes)"},{"path":"sesjo.github.io/ontodive/reference/data_nes.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Diving parameters of weanling Northern Elephant Seals in 2016 and 2018 — data_nes","text":"list containing one list per year, contains one dataset per individual. DATA > YEAR > INDIVIDUAL 2018 Dataset .id individual ID divenumber # dive date date time dive maxdepth maximum depth reached (m) dduration dive duration (s) botttime bottom duration (s) desctime descent duration (s) descrate descent rate (m/s) asctime ascent time (s) ascrate ascent rate (m/s) pdi post dive interval (s) dwigglesdesc # wiggles descent phase dwigglesbott # wiggles bottom phase dwigglesasc # wiggles ascent phase totvertdistbot vertical distance bottom (m) driftrate drift rate (m/s) divetype Dive type (transit, foraging, drift benthic) day_departure # days since departure lightatsurf light level surface lat latitude lon longitude dist_dep distance first data location point (m) sp species (nes) ssh sea surface height Copernicus psu Practical Salinity Unit Copernicus vel current velocity m/s derived Copernicus temp sea surface temperature Copernicus bathy bathymetry marmap package phase phase day (day night)","code":""},{"path":"sesjo.github.io/ontodive/reference/data_nes.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Diving parameters of weanling Northern Elephant Seals in 2016 and 2018 — data_nes","text":"roxanne@ucsc.edu","code":""},{"path":"sesjo.github.io/ontodive/reference/data_nes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Diving parameters of weanling Northern Elephant Seals in 2016 and 2018 — data_nes","text":"dataset obtained using following files: 2018070_nese0000annu_1790212_SubSample_iknos_DiveStat_RSB.csv 2018070_results-2-GPE3.csv 2018072_BothTrips_1790214_SubSample_iknos_DiveStat_RSB.csv 2018072_results-2-GPE3.csv 2018074_nese0000annu_1790218_SubSample_iknos_DiveStat_RSB.csv 2018080_nese0000annu_1790226_SubSample_iknos_DiveStat_RSB.csv 2018080_results-2-GPE3.csv","code":""},{"path":"sesjo.github.io/ontodive/reference/data_ses.html","id":null,"dir":"Reference","previous_headings":"","what":"Diving parameters of weanling Southern Elephant Seals in 2014 — data_ses","title":"Diving parameters of weanling Southern Elephant Seals in 2014 — data_ses","text":"list datasets containing diving parameters : 9 individuals 2014 data retrieved CEBC server (ftpmarin.cebc.cnrs.fr/EarlyLife/PostDoc%20Sam%20Cox/SES_PupData/RawData_2014-2015, please ask Baptiste Picard baptiste.picard@cebc.cnrs.fr get access)","code":""},{"path":"sesjo.github.io/ontodive/reference/data_ses.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Diving parameters of weanling Southern Elephant Seals in 2014 — data_ses","text":"","code":"data(data_ses)"},{"path":"sesjo.github.io/ontodive/reference/data_ses.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Diving parameters of weanling Southern Elephant Seals in 2014 — data_ses","text":"list containing one list per year, contains one dataset per individual. DATA > YEAR > INDIVIDUAL 2014 Dataset .id individual ID divenumber # dive date date time dive maxdepth maximum depth reached (m) dduration dive duration (s) botttime bottom duration (s) desctime descent duration (s) descrate descent rate (m/s) asctime ascent time (s) ascrate ascent rate (m/s) pdi post dive interval (s) dwigglesdesc # wiggles descent phase dwigglesbott # wiggles bottom phase dwigglesasc # wiggles ascent phase totvertdistbot vertical distance bottom (m) driftrate drift rate (m/s) divetype Dive type (transit, foraging, drift benthic) day_departure # days since departure lightatsurf light level surface lat latitude lon longitude dist_dep distance first data location point (m) sp species (ses) ssh sea surface height Copernicus data psu Practical Salinity Unit Copernicus vel current velocity m/s derived Copernicus temp sea surface temperature Copernicus bathy bathymetry marmap package phase phase day (day night)","code":""},{"path":"sesjo.github.io/ontodive/reference/data_ses.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Diving parameters of weanling Southern Elephant Seals in 2014 — data_ses","text":"baptiste.picard@cebc.cnrs.fr","code":""},{"path":"sesjo.github.io/ontodive/reference/data_ses.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Diving parameters of weanling Southern Elephant Seals in 2014 — data_ses","text":"dataset obtained using following files: Pup_140059.rds Pup_140060.rds Pup_140062.rds Pup_140062.rds Pup_140063.rds Pup_140068.rds Pup_140069.rds Pup_140072.rds Pup_140073.rds Pup_140075.rds","code":""},{"path":"sesjo.github.io/ontodive/reference/dot-n.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve elements' name of a list within apply function — .n","title":"Retrieve elements' name of a list within apply function — .n","text":"small function used within apply function retrieving element's name needed.","code":""},{"path":"sesjo.github.io/ontodive/reference/dot-n.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve elements' name of a list within apply function — .n","text":"","code":".n()"},{"path":"sesjo.github.io/ontodive/reference/dot-n.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve elements' name of a list within apply function — .n","text":"name element considered","code":""},{"path":"sesjo.github.io/ontodive/reference/dot-n.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Retrieve elements' name of a list within apply function — .n","text":"https://stackoverflow.com/questions/9950144/access-lapply-index-names-inside-fun","code":""},{"path":"sesjo.github.io/ontodive/reference/dot-n.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve elements' name of a list within apply function — .n","text":"","code":"# list creation A <- list(name_1 = NULL, name_2 = NULL)  # print name of each element using .n() sapply(A, function(x) .n()) #>   name_1   name_2  #> \"name_1\" \"name_2\""},{"path":"sesjo.github.io/ontodive/reference/flat_cor_mat.html","id":null,"dir":"Reference","previous_headings":"","what":"Flatten correlation matrix — flat_cor_mat","title":"Flatten correlation matrix — flat_cor_mat","text":"Flatten correlation matrix 2D dataframe.","code":""},{"path":"sesjo.github.io/ontodive/reference/flat_cor_mat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flatten correlation matrix — flat_cor_mat","text":"","code":"flat_cor_mat(cormat, pmat)"},{"path":"sesjo.github.io/ontodive/reference/flat_cor_mat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flatten correlation matrix — flat_cor_mat","text":"cormat correlation matrix pmat p-value matrix","code":""},{"path":"sesjo.github.io/ontodive/reference/flat_cor_mat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flatten correlation matrix — flat_cor_mat","text":"dataframe correlation p-values pairwise comparison","code":""},{"path":"sesjo.github.io/ontodive/reference/flat_cor_mat.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Flatten correlation matrix — flat_cor_mat","text":"http://www.sthda.com/french/wiki/matrice-de-correlation-formattage-et-visualisation","code":""},{"path":"sesjo.github.io/ontodive/reference/flat_cor_mat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flatten correlation matrix — flat_cor_mat","text":"","code":"# Dataset generation data_test <- data.frame(sapply(c(1:10), function(x) rnorm(10)))  # Correlation matrix calculation cor_test <- cor(data_test)  # Associated p-values cor_test_p <- ggcorrplot::cor_pmat(data_test)  # Flatten the correlation matrix flat_cor_mat(cor_test, cor_test_p) #>     row column         cor          p #>  1:  X1     X2 -0.35200610 0.31851364 #>  2:  X1     X3 -0.41984362 0.22707587 #>  3:  X2     X3  0.19659675 0.58618446 #>  4:  X1     X4  0.07140628 0.84459279 #>  5:  X2     X4 -0.37206910 0.28972133 #>  6:  X3     X4  0.10997781 0.76231229 #>  7:  X1     X5 -0.18858790 0.60182553 #>  8:  X2     X5 -0.08050319 0.82503611 #>  9:  X3     X5  0.11769013 0.74608920 #> 10:  X4     X5  0.03462722 0.92434372 #> 11:  X1     X6  0.64653072 0.04337734 #> 12:  X2     X6 -0.51530309 0.12742146 #> 13:  X3     X6 -0.02395939 0.94761891 #> 14:  X4     X6 -0.13212779 0.71596364 #> 15:  X5     X6 -0.23457311 0.51418604 #> 16:  X1     X7  0.37848813 0.28081606 #> 17:  X2     X7  0.06805252 0.85182262 #> 18:  X3     X7 -0.36237917 0.30344698 #> 19:  X4     X7 -0.12441507 0.73201582 #> 20:  X5     X7 -0.01070674 0.97658170 #> 21:  X6     X7 -0.20782182 0.56452077 #> 22:  X1     X8  0.56804667 0.08669288 #> 23:  X2     X8 -0.35173094 0.31891851 #> 24:  X3     X8 -0.38030169 0.27832725 #> 25:  X4     X8 -0.36655818 0.29748594 #> 26:  X5     X8 -0.07154508 0.84429378 #> 27:  X6     X8  0.55584484 0.09524304 #> 28:  X7     X8 -0.03296347 0.92797072 #> 29:  X1     X9  0.28341778 0.42746937 #> 30:  X2     X9  0.02423398 0.94701929 #> 31:  X3     X9 -0.47125120 0.16917805 #> 32:  X4     X9 -0.16732365 0.64405606 #> 33:  X5     X9  0.09247643 0.79942893 #> 34:  X6     X9  0.33937255 0.33737838 #> 35:  X7     X9 -0.19383676 0.59155763 #> 36:  X8     X9  0.43549186 0.20840191 #> 37:  X1    X10  0.12052527 0.74014755 #> 38:  X2    X10 -0.31566239 0.37427705 #> 39:  X3    X10 -0.59463757 0.06980958 #> 40:  X4    X10  0.31711717 0.37195792 #> 41:  X5    X10 -0.04652086 0.89845558 #> 42:  X6    X10 -0.35571457 0.31308310 #> 43:  X7    X10  0.59563812 0.06922006 #> 44:  X8    X10 -0.17952589 0.61970119 #> 45:  X9    X10 -0.19158741 0.59594999 #>     row column         cor          p"},{"path":"sesjo.github.io/ontodive/reference/format_col.html","id":null,"dir":"Reference","previous_headings":"","what":"Format columns — format_col","title":"Format columns — format_col","text":"Format columns dataset removing capital letters, bracket transform white space underscore","code":""},{"path":"sesjo.github.io/ontodive/reference/format_col.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format columns — format_col","text":"","code":"format_col(col_names)"},{"path":"sesjo.github.io/ontodive/reference/format_col.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format columns — format_col","text":"col_names vector character containing column names formatted","code":""},{"path":"sesjo.github.io/ontodive/reference/format_col.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format columns — format_col","text":"input correctly formatted","code":""},{"path":"sesjo.github.io/ontodive/reference/format_col.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format columns — format_col","text":"","code":"# format several vectors of characters format_col(c(\"lkjez alzkj\", \"kjfe[lkjz]\", \"lkjee [lkj]\")) #> [1] \"lkjezalzkj\" \"kjfe_lkjz\"  \"lkjee_lkj\""},{"path":"sesjo.github.io/ontodive/reference/get_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve data — get_data","title":"Retrieve data — get_data","text":"function first look datasets ontodive package. datasets included, tried download dataset based DOI pre-reserved Dryad submitting paper. somehow still work asked enter DOI dataset looking .","code":""},{"path":"sesjo.github.io/ontodive/reference/get_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve data — get_data","text":"","code":"get_data(species = \"all\")"},{"path":"sesjo.github.io/ontodive/reference/get_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve data — get_data","text":"species \"\", \"nes\" \"ses\" retrieve respectively dataset species one associated northern southern elephant seals.","code":""},{"path":"sesjo.github.io/ontodive/reference/get_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve data — get_data","text":"table class data.table species = \"\", otherwise list year individual","code":""},{"path":"sesjo.github.io/ontodive/reference/get_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve data — get_data","text":"","code":"if (FALSE) { # retrieve all data get_data(\"all\") }"},{"path":"sesjo.github.io/ontodive/reference/gt_plt_bar_stack_extra.html","id":null,"dir":"Reference","previous_headings":"","what":"Add a percent stacked barchart in place of existing data. — gt_plt_bar_stack_extra","title":"Add a percent stacked barchart in place of existing data. — gt_plt_bar_stack_extra","text":"gt_plt_bar_stack_extra copy paste function gt_plt_bar_stack available gtExtras package limitation 3 user-specified risen 4. takes existing gt_tbl object converts existing values percent stacked barchart. bar chart represent either 2, 3 4 user-specified values per row, requires list column ahead time. palette labels need equal length. values must either add 100 .e. percentage points using position = 'fill', can raw values position = 'stack'. Note labels can controlled via fmt_fn argument ⁠scales::lab_xxx family function.","code":""},{"path":"sesjo.github.io/ontodive/reference/gt_plt_bar_stack_extra.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add a percent stacked barchart in place of existing data. — gt_plt_bar_stack_extra","text":"","code":"gt_plt_bar_stack_extra(   gt_object,   column = NULL,   palette = c(\"#ff4343\", \"#bfbfbf\", \"#0a1c2b\", \"#e1be6a\"),   labels = c(\"Group 1\", \"Group 2\", \"Group 3\", \"Group 4\"),   position = \"fill\",   width = 70,   fmt_fn = label_number(scale_cut = cut_short_scale(), trim = TRUE) )"},{"path":"sesjo.github.io/ontodive/reference/gt_plt_bar_stack_extra.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add a percent stacked barchart in place of existing data. — gt_plt_bar_stack_extra","text":"gt_object existing gt table object class gt_tbl column column wherein percent stacked barchart replace existing data. Note data must represented list numeric values ahead time. palette color palette length 2 3, represented either hex colors (#ff4343) named colors (red). labels vector strings length 2 3, representing labels bar chart, colored according palette well. position string indicator passed ggplot2 indicating bar percent total fill stacked raw values stack. width integer representing width bar chart pixels. fmt_fn specific function ⁠scales::lab_xxx⁠ family. Defaults scales::label_number","code":""},{"path":"sesjo.github.io/ontodive/reference/gt_plt_bar_stack_extra.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add a percent stacked barchart in place of existing data. — gt_plt_bar_stack_extra","text":"object class gt_tbl.","code":""},{"path":"sesjo.github.io/ontodive/reference/gt_plt_bar_stack_extra.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Add a percent stacked barchart in place of existing data. — gt_plt_bar_stack_extra","text":"https://github.com/jthomasmock/gtExtras/blob/HEAD/R/gt_pct_bar.R","code":""},{"path":[]},{"path":"sesjo.github.io/ontodive/reference/gt_plt_bar_stack_extra.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add a percent stacked barchart in place of existing data. — gt_plt_bar_stack_extra","text":"","code":"if (FALSE) { # load library library(gt) library(dplyr)  # dummy dataset ex_df <- dplyr::tibble(   x = c(     \"Example 1\", \"Example 1\",     \"Example 1\", \"Example 1\", \"Example 2\", \"Example 2\", \"Example 2\", \"Example 2\",     \"Example 3\", \"Example 3\", \"Example 3\", \"Example 3\", \"Example 4\", \"Example 4\", \"Example 4\",     \"Example 4\"   ),   measure = c(     \"Measure 1\", \"Measure 2\",     \"Measure 3\", \"Measure 4\", \"Measure 1\", \"Measure 2\", \"Measure 3\", \"Measure 4\",     \"Measure 1\", \"Measure 2\", \"Measure 3\", \"Measure 4\", \"Measure 1\", \"Measure 2\",     \"Measure 3\", \"Measure 4\"   ),   data = c(30, 20, 40, 10, 30, 30, 20, 20, 30, 10, 30, 30, 30, 50, 10, 10) )  # display results ex_df %>%   group_by(x) %>%   summarise(list_data = list(data)) %>%   gt() %>%   gt_plt_bar_stack_extra(column = list_data) }"},{"path":"sesjo.github.io/ontodive/reference/is_outlier.html","id":null,"dir":"Reference","previous_headings":"","what":"Find outliers using interquartile range rule — is_outlier","title":"Find outliers using interquartile range rule — is_outlier","text":"function aims finding outliers vector using interquartile range rule","code":""},{"path":"sesjo.github.io/ontodive/reference/is_outlier.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find outliers using interquartile range rule — is_outlier","text":"","code":"is_outlier(x)"},{"path":"sesjo.github.io/ontodive/reference/is_outlier.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find outliers using interquartile range rule — is_outlier","text":"x vector outliers need found","code":""},{"path":"sesjo.github.io/ontodive/reference/is_outlier.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find outliers using interquartile range rule — is_outlier","text":"boolean vector, TRUE outliers, FALSE ","code":""},{"path":"sesjo.github.io/ontodive/reference/is_outlier.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find outliers using interquartile range rule — is_outlier","text":"","code":"# generate data from gaussian and exponential distribution X <- sample(c(rnorm(100), c(rexp(50), -rexp(50))))  # plot data plot(X, col = ifelse(is_outlier(X), \"red\", \"black\"))"},{"path":"sesjo.github.io/ontodive/reference/location_treatment.html","id":null,"dir":"Reference","previous_headings":"","what":"Treat location data with a continuous-time state-space model — location_treatment","title":"Treat location data with a continuous-time state-space model — location_treatment","text":"Using fit_ssm function aniMotum package, function \"clean\" location data used analysis dive scale.","code":""},{"path":"sesjo.github.io/ontodive/reference/location_treatment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Treat location data with a continuous-time state-space model — location_treatment","text":"","code":"location_treatment(   data,   model = \"crw\",   time.step = 1,   vmax = 3,   with_plot = FALSE,   export = NULL )"},{"path":"sesjo.github.io/ontodive/reference/location_treatment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Treat location data with a continuous-time state-space model — location_treatment","text":"data Dataset observation, usually file \\*Argos.csv \\*Location.csv files model Choose fit either simple random walk (\"rw\") correlated random walk (\"crw\") continuous-time process model time.step options: 1) regular time interval, hours, predict ; 2) vector prediction times, possibly regular, must specified data.frame id POSIXt dates; 3) NA - turns prediction locations estimated observation times. vmax max travel rate (m/s) passed sda identify outlier locations with_plot diagnostic plot export export new generated dataset","code":""},{"path":"sesjo.github.io/ontodive/reference/location_treatment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Treat location data with a continuous-time state-space model — location_treatment","text":"dataset new location data","code":""},{"path":"sesjo.github.io/ontodive/reference/location_treatment.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Treat location data with a continuous-time state-space model — location_treatment","text":"run_aniMotum_generic.R (tkeates@ucsc.edu) https://ianjonsen.github.io/aniMotum/","code":""},{"path":[]},{"path":"sesjo.github.io/ontodive/reference/location_treatment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Treat location data with a continuous-time state-space model — location_treatment","text":"","code":"# load library library(aniMotum) library(data.table)  # run this function on sese dataset included in aniMotum package output <- location_treatment(copy(sese), with_plot = TRUE) #>  #>  #>  #>"},{"path":"sesjo.github.io/ontodive/reference/matlab_to_posix.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Matlab datenum to POSIX — matlab_to_posix","title":"Convert Matlab datenum to POSIX — matlab_to_posix","text":"Small function convert Matlab datenum POSIX time","code":""},{"path":"sesjo.github.io/ontodive/reference/matlab_to_posix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Matlab datenum to POSIX — matlab_to_posix","text":"","code":"matlab_to_posix(x, timez = \"UTC\")"},{"path":"sesjo.github.io/ontodive/reference/matlab_to_posix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Matlab datenum to POSIX — matlab_to_posix","text":"x column Matlab datenum timez time zone used","code":""},{"path":"sesjo.github.io/ontodive/reference/matlab_to_posix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Matlab datenum to POSIX — matlab_to_posix","text":"vector POSIXct","code":""},{"path":"sesjo.github.io/ontodive/reference/matlab_to_posix.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Convert Matlab datenum to POSIX — matlab_to_posix","text":"http://lukemiller.org/index.php/2011/02/converting-matlab--r-date--time-values/","code":""},{"path":"sesjo.github.io/ontodive/reference/matlab_to_posix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert Matlab datenum to POSIX — matlab_to_posix","text":"","code":"matlab_to_posix(c(737182.4)) #> [1] \"2018-05-02 09:36:00 UTC\""},{"path":"sesjo.github.io/ontodive/reference/plot_comp.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the evolution of a diving parameter accross time between two populations — plot_comp","title":"Plot the evolution of a diving parameter accross time between two populations — plot_comp","text":"function approximates relationship considered diving behavior time order better represent evolution smooth curve, rather scatterplot.","code":""},{"path":"sesjo.github.io/ontodive/reference/plot_comp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the evolution of a diving parameter accross time between two populations — plot_comp","text":"","code":"plot_comp(   data,   diving_parameter = NULL,   group_to_compare = \"sp\",   time = \"day_departure\",   id = \".id\",   nb_days = 100,   bs = \"cs\",   k = 6,   alpha_point = 0.01,   alpha_ribbon = 0.4,   linetype_ribbon = 2,   colours = NULL,   ribbon = TRUE,   point = TRUE,   individual = TRUE,   populational = TRUE,   rows = NULL,   cols = NULL,   scales = \"fixed\",   method = \"REML\",   export_data_model = FALSE )"},{"path":"sesjo.github.io/ontodive/reference/plot_comp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the evolution of a diving parameter accross time between two populations — plot_comp","text":"data dataset containing required information diving_parameter colname associated diving parameter represent group_to_compare colname associated groups compare time colname associated time id colname associated individual nb_days many days represent bs Smooth terms GAM k dimension basis used represent smooth term alpha_point transparency point alpha_ribbon transparency ribbon linetype_ribbon Line type ribbon border colours colours use ribbon confidence interval added point points displayed individual individuals curves displayed populational populational curve displayed rows colname used facet row cols colname used facet column scales scales shared across facets (default, \"fixed\") method smoothing parameter estimation method GAM (default REML) export_data_model Boolean export data underlying model","code":""},{"path":"sesjo.github.io/ontodive/reference/plot_comp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the evolution of a diving parameter accross time between two populations — plot_comp","text":"Return ggplot","code":""},{"path":"sesjo.github.io/ontodive/reference/plot_comp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot the evolution of a diving parameter accross time between two populations — plot_comp","text":"function fits GAM species grouping factor random effect (intercept + slope) individual (.e. diving parameter ~ species + s(time) + (1 time | individual). allows represent curve species, also access curve associated individual.","code":""},{"path":"sesjo.github.io/ontodive/reference/plot_comp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot the evolution of a diving parameter accross time between two populations — plot_comp","text":"https://stats.stackexchange.com/questions/403772/different-ways--modelling-interactions--continuous--categorical-pred https://github.com/DistanceDevelopment/dsm/wiki/---default-smoothing-method-%22REML%22-rather--%22GCV.Cp%22%3F James Grecian. (2022). jamesgrecian/harpPup: v1.0 (v1.0). Zenodo. https://doi.org/10.5281/zenodo.5901391","code":""},{"path":[]},{"path":"sesjo.github.io/ontodive/reference/plot_comp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot the evolution of a diving parameter accross time between two populations — plot_comp","text":"","code":"if (FALSE) { # load data data_nes <- get_data(\"nes\") data_ses <- get_data(\"ses\")  # combine data_comp <- rbind(   rbindlist(data_nes$year_2018),   rbindlist(data_ses$year_2014),   use.names = T,   fill = T )  # plot plot_comp(data_comp, \"maxdepth\") }"},{"path":"sesjo.github.io/ontodive/reference/plot_ind.html","id":null,"dir":"Reference","previous_headings":"","what":"Display summary information for a seal — plot_ind","title":"Display summary information for a seal — plot_ind","text":"function displays several key information regarding seal.","code":""},{"path":"sesjo.github.io/ontodive/reference/plot_ind.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Display summary information for a seal — plot_ind","text":"","code":"plot_ind(data_seal, col_text = \"black\", col_back = \"transparent\")"},{"path":"sesjo.github.io/ontodive/reference/plot_ind.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Display summary information for a seal — plot_ind","text":"data_seal table containing information animal's diving behavior (maxdepth, lat, lon, date, driftrate) col_text color text col_back color background","code":""},{"path":"sesjo.github.io/ontodive/reference/plot_ind.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Display summary information for a seal — plot_ind","text":"ggplot object contains four figures","code":""},{"path":"sesjo.github.io/ontodive/reference/plot_ind.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Display summary information for a seal — plot_ind","text":"map seal's trip sea color code based number days since departure max depth reached dives across time evolution daily median drift rate across time evolution ADL across time","code":""},{"path":"sesjo.github.io/ontodive/reference/plot_ind.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Display summary information for a seal — plot_ind","text":"","code":"if (FALSE) { # load data data_nes <- get_data(\"nes\")  # plot result plot_ind(data_nes$year_2018$ind_2018070) }"},{"path":"sesjo.github.io/ontodive/reference/theme_jjo.html","id":null,"dir":"Reference","previous_headings":"","what":"A personnalised ggplot theme — theme_jjo","title":"A personnalised ggplot theme — theme_jjo","text":"personnalised ggplot theme","code":""},{"path":"sesjo.github.io/ontodive/reference/theme_jjo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A personnalised ggplot theme — theme_jjo","text":"","code":"theme_jjo(base_size = 12)"},{"path":"sesjo.github.io/ontodive/reference/theme_jjo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A personnalised ggplot theme — theme_jjo","text":"base_size Font size","code":""},{"path":"sesjo.github.io/ontodive/reference/theme_jjo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A personnalised ggplot theme — theme_jjo","text":"ggplot theme","code":""},{"path":"sesjo.github.io/ontodive/reference/theme_jjo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"A personnalised ggplot theme — theme_jjo","text":"https://benjaminlouis-stat.fr/en/blog/2020-05-21-astuces-ggplot-rmarkdown/","code":""},{"path":"sesjo.github.io/ontodive/reference/theme_jjo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A personnalised ggplot theme — theme_jjo","text":"","code":"# load package library(ggplot2)  # plot ggplot(cars) +   geom_point(aes(x = speed, y = dist)) +   theme_jjo()"}]
